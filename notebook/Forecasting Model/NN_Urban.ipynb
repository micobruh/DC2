{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Urban.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa1pr4HvXY5W",
        "outputId": "422dd247-7083-46ba-e5d7-f00c87795e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trWNrG0LbKri"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Input, Dense, LSTM, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras_tuner.tuners import BayesianOptimization\n",
        "from keras.optimizer_v2 import adam as adam_v2\n",
        "import os\n",
        "import math\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "pHixuBZvcDhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea32d4d-2ab0-4b7e-ab13-f815f11eaf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_org = pd.read_csv(\"/content/drive/MyDrive/DC2/all_variables.csv\")\n",
        "df_org"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "drPtZvXwcIBb",
        "outputId": "ebe4f67d-0434-4c46-a7cc-8a18f08dd783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Year  Month  LSOA_code            LSOA_name  Type_I_crime_amount  \\\n",
              "0        2011      1  E01000001  City of London 001A                    2   \n",
              "1        2011      2  E01000001  City of London 001A                    1   \n",
              "2        2011      3  E01000001  City of London 001A                    6   \n",
              "3        2011      4  E01000001  City of London 001A                    1   \n",
              "4        2011      6  E01000001  City of London 001A                    1   \n",
              "...       ...    ...        ...                  ...                  ...   \n",
              "3286689  2021      6  W01001958         Swansea 025H                    6   \n",
              "3286690  2021      7  W01001958         Swansea 025H                    4   \n",
              "3286691  2021      8  W01001958         Swansea 025H                    9   \n",
              "3286692  2021      9  W01001958         Swansea 025H                    4   \n",
              "3286693  2021     10  W01001958         Swansea 025H                    7   \n",
              "\n",
              "         Total_month  Type_II_crime_amount  \n",
              "0                  1                     8  \n",
              "1                  2                     8  \n",
              "2                  3                     4  \n",
              "3                  4                     4  \n",
              "4                  6                    15  \n",
              "...              ...                   ...  \n",
              "3286689          126                    16  \n",
              "3286690          127                    11  \n",
              "3286691          128                    10  \n",
              "3286692          129                    16  \n",
              "3286693          130                     9  \n",
              "\n",
              "[3286694 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbc767d2-88cf-4e40-a1c8-85d7d4172b42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>LSOA_code</th>\n",
              "      <th>LSOA_name</th>\n",
              "      <th>Type_I_crime_amount</th>\n",
              "      <th>Total_month</th>\n",
              "      <th>Type_II_crime_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>E01000001</td>\n",
              "      <td>City of London 001A</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>2</td>\n",
              "      <td>E01000001</td>\n",
              "      <td>City of London 001A</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>E01000001</td>\n",
              "      <td>City of London 001A</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>E01000001</td>\n",
              "      <td>City of London 001A</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011</td>\n",
              "      <td>6</td>\n",
              "      <td>E01000001</td>\n",
              "      <td>City of London 001A</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3286689</th>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "      <td>W01001958</td>\n",
              "      <td>Swansea 025H</td>\n",
              "      <td>6</td>\n",
              "      <td>126</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3286690</th>\n",
              "      <td>2021</td>\n",
              "      <td>7</td>\n",
              "      <td>W01001958</td>\n",
              "      <td>Swansea 025H</td>\n",
              "      <td>4</td>\n",
              "      <td>127</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3286691</th>\n",
              "      <td>2021</td>\n",
              "      <td>8</td>\n",
              "      <td>W01001958</td>\n",
              "      <td>Swansea 025H</td>\n",
              "      <td>9</td>\n",
              "      <td>128</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3286692</th>\n",
              "      <td>2021</td>\n",
              "      <td>9</td>\n",
              "      <td>W01001958</td>\n",
              "      <td>Swansea 025H</td>\n",
              "      <td>4</td>\n",
              "      <td>129</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3286693</th>\n",
              "      <td>2021</td>\n",
              "      <td>10</td>\n",
              "      <td>W01001958</td>\n",
              "      <td>Swansea 025H</td>\n",
              "      <td>7</td>\n",
              "      <td>130</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3286694 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc767d2-88cf-4e40-a1c8-85d7d4172b42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbc767d2-88cf-4e40-a1c8-85d7d4172b42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbc767d2-88cf-4e40-a1c8-85d7d4172b42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# E01000005 for Urban\n",
        "# E01030759 for Town and Fringe\n",
        "# E01020795 for Village Hamlet & Isolated Dwellings"
      ],
      "metadata": {
        "id": "Aez85JlP7X4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the data from a given LSOA code\n",
        "df_need = df_org[df_org['LSOA_code'] == 'E01000005'].reset_index(drop = True)\n",
        "df_need = df_need[['Total_month', 'Type_I_crime_amount', 'Type_II_crime_amount']]\n",
        "df_need = df_need[df_need['Total_month'] <= 108]\n",
        "df_need.drop(columns = 'Total_month', inplace = True)\n",
        "df_need"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "n1TQ010scaMl",
        "outputId": "b0ccd7da-3a4d-4b09-af2a-9efa4c085f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Type_I_crime_amount  Type_II_crime_amount\n",
              "0                      7                    21\n",
              "1                     10                    30\n",
              "2                      6                    31\n",
              "3                      5                    26\n",
              "4                      2                    37\n",
              "..                   ...                   ...\n",
              "103                   12                    30\n",
              "104                    8                    34\n",
              "105                   12                    34\n",
              "106                   12                    40\n",
              "107                   15                    34\n",
              "\n",
              "[108 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cd2da11-b64f-45d2-b95a-6f9b505050a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type_I_crime_amount</th>\n",
              "      <th>Type_II_crime_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>12</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>12</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>15</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cd2da11-b64f-45d2-b95a-6f9b505050a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cd2da11-b64f-45d2-b95a-6f9b505050a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cd2da11-b64f-45d2-b95a-6f9b505050a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(sequences) - 1:\n",
        "          break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i: end_ix], sequences[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "lJOvnBI5Hg5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter searching if necessary\n",
        "\n",
        "def build_model(hp):\n",
        "    # Build the LSTM model with 2 LSTM layers and 1 Dense layer\n",
        "    input = Input(shape = (12, 2))\n",
        "    l1 = LSTM(units = hp.Int('units_1', min_value = 50, max_value = 300, step = 50), return_sequences = True, dropout = 0.2)(input)\n",
        "    b1 = BatchNormalization()(l1)\n",
        "    l2 = LSTM(units = hp.Int('units_2', min_value = 50, max_value = 300, step = 50), return_sequences = False, dropout = 0.2)(b1)\n",
        "    b2 = BatchNormalization()(l2)\n",
        "    output = Dense(2)(b2)\n",
        "    model = Model(input, output)\n",
        "\n",
        "    # The optimizer is Adam\n",
        "    opt = adam_v2.Adam(learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4, 2e-2, 2e-3, 2e-4]))\n",
        "    model.compile(loss = 'mse', optimizer = opt, metrics = ['mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def find_best_model():\n",
        "    # Example of splitting the data when time step is 12 months: \n",
        "    # Training data has data from 1st month to 24th month\n",
        "    # Val data has data from 13th month to 36th month\n",
        "    # Test data predicts new data using data from 25th month to 36th month\n",
        "    train_data = df_need.to_numpy()[: 96]\n",
        "    val_data = df_need.to_numpy()[84: 108]\n",
        "    # Split x and y arrays using sliding window approach\n",
        "    x_train, y_train = split_sequences(train_data, 12)\n",
        "    x_val, y_val = split_sequences(val_data, 12)\n",
        "    bayesian_opt_tuner = BayesianOptimization(build_model, objective = 'mse',\n",
        "        max_trials = 216,\n",
        "        executions_per_trial = 1,\n",
        "        directory = '/content/drive/MyDrive/DC2/tune/Urban/',\n",
        "        project_name = 'kerastuner_bayesian_poc',\n",
        "        overwrite = True)\n",
        "\n",
        "    bayesian_opt_tuner.search(x_train, y_train, epochs = 500, validation_data = (x_val, y_val))\n",
        "\n",
        "    bayes_opt_model_best_model = bayesian_opt_tuner.get_best_models(num_models = 1)\n",
        "    model = bayes_opt_model_best_model[0]\n",
        "    return model\n",
        "\n",
        "#model = find_best_model()\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "9QqvesAPTHgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(df, train_nr, prediction_nr, comparison, model_exist, n_steps=12):\n",
        "    with tf.device(device_name):\n",
        "        # Example of splitting the data when time step is 12 months: \n",
        "        # Training data has data from 1st month to 24th month\n",
        "        # Val data has data from 13th month to 36th month\n",
        "        # Test data predicts new data using data from 25th month to 36th month\n",
        "        train_data = df.to_numpy()[: train_nr - n_steps]\n",
        "        val_data = df.to_numpy()[train_nr - n_steps * 2: train_nr]\n",
        "        # Split x and y arrays using sliding window approach\n",
        "        x_train, y_train = split_sequences(train_data, n_steps)\n",
        "        x_val, y_val = split_sequences(val_data, n_steps)\n",
        "\n",
        "        if model_exist == \"Nil\":\n",
        "            # Build the LSTM model with 2 LSTM layers and 1 Dense layer\n",
        "            input = Input(shape = (n_steps, 2))\n",
        "            l1 = LSTM(50, return_sequences = True, dropout = 0.2)(input)\n",
        "            b1 = BatchNormalization()(l1)\n",
        "            l2 = LSTM(50, return_sequences = False, dropout = 0.2)(b1)\n",
        "            b2 = BatchNormalization()(l2)\n",
        "            output = Dense(2)(b2)\n",
        "            model = Model(input, output)\n",
        "\n",
        "            # The optimizer is Adam\n",
        "            opt = adam_v2.Adam(learning_rate = 0.005, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08)\n",
        "\n",
        "            # The loss used in model training is mean_squared_error because it is crime number prediction\n",
        "            model.compile(loss = 'mse', optimizer = opt)\n",
        "\n",
        "        else:\n",
        "            model = model_exist\n",
        "        \n",
        "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 200)\n",
        "        checkpoint_filepath = '/content/drive/MyDrive/DC2/model/Urban/' + str(train_nr) + '/weights.{epoch:02d}.h5'\n",
        "        model_checkpoint_callback = ModelCheckpoint(filepath = checkpoint_filepath, monitor = 'val_loss', mode = 'min', save_best_only = True)\n",
        "        lr_reducer = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 50, verbose = 0, mode = 'min', min_delta = 0.0001, cooldown = 0, min_lr = 0)\n",
        "\n",
        "        # Fit the model with 1000 epoches and batch size 64\n",
        "        # Validation data is used here for evaluation during the training process\n",
        "        model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 1000, batch_size = 32, callbacks = [model_checkpoint_callback, lr_reducer, early_stopping])\n",
        "\n",
        "        # Look for all file directories in the folder\n",
        "        directory = \"/content/drive/MyDrive/DC2/model/Urban/\" + str(train_nr) + '/'\n",
        "        all_file_lst = []\n",
        "        for root, subdirectories, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                all_file_lst.append(os.path.join(root, file))\n",
        "        # Load the best model trained\n",
        "        model = load_model(all_file_lst[-1])\n",
        "\n",
        "        # Make predictions from testing data\n",
        "        # Pred x is a list of predicted data used\n",
        "        # Pred y is a list of predicted result\n",
        "        # Get the last 12 results from overall training data for prediction data in pred x\n",
        "        pred_x = np.array(list(val_data[-(n_steps): ]))\n",
        "        pred_x = pred_x.reshape((1, pred_x.shape[0], pred_x.shape[1]))\n",
        "        # Initialize pred y as empty array\n",
        "        pred_y = np.empty((1, 1, 2), int)\n",
        "        for i in range(prediction_nr):\n",
        "            # Always round off the latest prediction to integer because number of crime can only be integer\n",
        "            prediction = np.round(model.predict(pred_x))\n",
        "            # Update pred y \n",
        "            pred_y = np.append(pred_y, [prediction], axis = 1)\n",
        "            # Update pred x by feeding the latest prediction result as latest feature\n",
        "            pred_x = np.append(pred_x, [prediction], axis = 1)\n",
        "            # Update pred x by removing the 1st row because of the timestep size\n",
        "            pred_x = pred_x[: , 1: , : ]\n",
        "        # Remove the 1st row of pred y because when initializing array, random numbers are assigned which are not actual results\n",
        "        pred_y = pred_y[: , 1: , : ]\n",
        "        \n",
        "        df_predict = pd.DataFrame(columns = ['Type_I_crime_amount', 'Type_II_crime_amount'])\n",
        "        df_predict['Type_I_crime_amount'] = np.round(pred_y[: , : , 0])[0]\n",
        "        df_predict['Type_II_crime_amount'] = np.round(pred_y[: , : , 1])[0]\n",
        "\n",
        "        if comparison == False:\n",
        "            return df_predict\n",
        "        else:\n",
        "            # Compute RMSE, MAE and R2 by comparing predicted result from actual crime number\n",
        "            y_true = df[train_nr: (train_nr + prediction_nr)]\n",
        "            rmse_1 = math.sqrt(mean_squared_error(y_true['Type_I_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist()))\n",
        "            rmse_2 = math.sqrt(mean_squared_error(y_true['Type_II_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist()))\n",
        "            mae_1 = mean_absolute_error(y_true['Type_I_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist())\n",
        "            mae_2 = mean_absolute_error(y_true['Type_II_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist())\n",
        "            medae_1 = median_absolute_error(y_true['Type_I_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist())\n",
        "            medae_2 = median_absolute_error(y_true['Type_II_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist())\n",
        "            r2_1 = r2_score(y_true['Type_I_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist())\n",
        "            r2_2 = r2_score(y_true['Type_II_crime_amount'].tolist(), df_predict['Type_I_crime_amount'].tolist())\n",
        "            return df_predict, rmse_1, rmse_2, mae_1, mae_2, medae_1, medae_2, r2_1, r2_2"
      ],
      "metadata": {
        "id": "MPcroSZKb3rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_compare_predict = pd.DataFrame(columns = ['Type_I_crime_amount', 'Type_II_crime_amount'])\n",
        "rmse_lst_1 = []\n",
        "rmse_lst_2 = []\n",
        "mae_lst_1 = []\n",
        "mae_lst_2 = []\n",
        "medae_lst_1 = []\n",
        "medae_lst_2 = []\n",
        "r2_lst_1 = []\n",
        "r2_lst_2 = []\n",
        "\n",
        "# Month Forward-Chaining Cross Validation Approach is used below\n",
        "for i in tqdm(range(6)):\n",
        "    df_small, rmse_1_small, rmse_2_small, mae_1_small, mae_2_small, medae_1_small, medae_2_small, r2_1_small, r2_2_small = train(df_need, 36 + 12 * i, 12, True, \"Nil\")\n",
        "    df_compare_predict = pd.concat([df_compare_predict, df_small])\n",
        "    rmse_lst_1.append(rmse_1_small)\n",
        "    rmse_lst_2.append(rmse_2_small)\n",
        "    mae_lst_1.append(mae_1_small)\n",
        "    mae_lst_2.append(mae_2_small)\n",
        "    medae_lst_1.append(medae_1_small)\n",
        "    medae_lst_2.append(medae_2_small)    \n",
        "    r2_lst_1.append(r2_1_small)\n",
        "    r2_lst_2.append(r2_2_small)\n",
        "\n",
        "df_compare_predict"
      ],
      "metadata": {
        "id": "-IJhOhnlsugc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db97711e-20ee-465d-ed90-cc9478393320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 12s 12s/step - loss: 783.1092 - val_loss: 563.1605 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 775.1265 - val_loss: 560.5746 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 779.1465 - val_loss: 555.9689 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 772.5908 - val_loss: 552.1393 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 770.3919 - val_loss: 551.5323 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 769.4590 - val_loss: 549.7505 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 765.5942 - val_loss: 548.4084 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 772.0591 - val_loss: 544.8023 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 759.7080 - val_loss: 541.3764 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 756.8743 - val_loss: 540.4793 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 751.9614 - val_loss: 538.7198 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 747.7443 - val_loss: 536.8215 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 740.4246 - val_loss: 534.1083 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 749.2437 - val_loss: 528.0388 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 735.7081 - val_loss: 521.6121 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 739.0850 - val_loss: 516.2325 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 738.1755 - val_loss: 513.4888 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 733.2325 - val_loss: 508.5761 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 731.7289 - val_loss: 504.0961 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 714.9438 - val_loss: 498.5741 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 724.6634 - val_loss: 492.1477 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 725.3977 - val_loss: 483.9973 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 718.3938 - val_loss: 473.6777 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 716.1294 - val_loss: 466.3937 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 710.0547 - val_loss: 460.4813 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 699.3701 - val_loss: 456.9400 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 695.1221 - val_loss: 452.1389 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 696.8495 - val_loss: 448.6526 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 690.2775 - val_loss: 443.4885 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 679.4719 - val_loss: 439.2965 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 708.6001 - val_loss: 432.2140 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 684.8667 - val_loss: 427.5852 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 703.5703 - val_loss: 422.5389 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 670.9567 - val_loss: 417.0737 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 658.6226 - val_loss: 410.3759 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 659.1069 - val_loss: 402.1740 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 653.3900 - val_loss: 393.1582 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 656.0265 - val_loss: 385.1564 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 650.3782 - val_loss: 377.3954 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 630.7852 - val_loss: 369.2733 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 625.4001 - val_loss: 362.7252 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 614.9736 - val_loss: 354.9923 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 615.6530 - val_loss: 345.3668 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 608.5136 - val_loss: 336.8447 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 601.9554 - val_loss: 329.8217 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 595.4527 - val_loss: 323.8846 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 591.9482 - val_loss: 318.0203 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 582.1918 - val_loss: 312.5345 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 588.2134 - val_loss: 307.7772 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 572.7801 - val_loss: 302.1186 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 563.5279 - val_loss: 295.1950 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 559.5853 - val_loss: 289.5759 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 547.3379 - val_loss: 285.0251 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 537.1381 - val_loss: 280.2440 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 536.1104 - val_loss: 275.9192 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 519.7391 - val_loss: 272.5346 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 511.2160 - val_loss: 268.4077 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 505.0142 - val_loss: 264.2635 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 502.7098 - val_loss: 259.7362 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 486.3154 - val_loss: 254.8411 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 478.6985 - val_loss: 249.8878 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 477.1372 - val_loss: 244.0833 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 464.2411 - val_loss: 238.3823 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 450.7173 - val_loss: 231.6376 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 451.2899 - val_loss: 224.7727 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 445.0959 - val_loss: 217.4068 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 423.5608 - val_loss: 207.6939 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 414.8293 - val_loss: 196.2999 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 397.7022 - val_loss: 184.6674 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 395.5894 - val_loss: 173.2932 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 383.0291 - val_loss: 161.5907 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 395.3370 - val_loss: 152.2367 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 368.8030 - val_loss: 144.1890 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 376.4723 - val_loss: 140.6224 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 369.2516 - val_loss: 134.3384 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 351.6321 - val_loss: 129.8647 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 341.7986 - val_loss: 128.0073 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 326.4606 - val_loss: 125.0482 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 328.5010 - val_loss: 125.3028 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 315.4412 - val_loss: 123.8533 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 305.0011 - val_loss: 124.1628 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 293.3036 - val_loss: 122.8669 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 289.0713 - val_loss: 121.0998 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 276.8881 - val_loss: 117.1590 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 273.8094 - val_loss: 112.1126 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 259.7298 - val_loss: 107.6995 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 251.4820 - val_loss: 103.9231 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 244.6582 - val_loss: 98.8538 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 236.2341 - val_loss: 92.2364 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 236.6243 - val_loss: 87.9223 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 220.4872 - val_loss: 84.2151 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 222.0428 - val_loss: 82.5924 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 230.6905 - val_loss: 81.5720 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 207.3522 - val_loss: 82.0140 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 192.3003 - val_loss: 81.2802 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 192.2504 - val_loss: 79.9143 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 175.5148 - val_loss: 77.3277 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 171.1520 - val_loss: 75.0881 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 186.5030 - val_loss: 72.5523 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 160.9507 - val_loss: 69.3612 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 159.8994 - val_loss: 64.8833 - lr: 0.0050\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 142.7719 - val_loss: 60.2348 - lr: 0.0050\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 152.5049 - val_loss: 57.0406 - lr: 0.0050\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 146.8058 - val_loss: 53.3879 - lr: 0.0050\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 130.5223 - val_loss: 50.6233 - lr: 0.0050\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 124.6710 - val_loss: 48.6431 - lr: 0.0050\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 146.8495 - val_loss: 44.6148 - lr: 0.0050\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 112.0303 - val_loss: 40.7225 - lr: 0.0050\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 114.2910 - val_loss: 36.3976 - lr: 0.0050\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 99.0644 - val_loss: 32.1602 - lr: 0.0050\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 97.3593 - val_loss: 28.4735 - lr: 0.0050\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 88.1370 - val_loss: 25.1035 - lr: 0.0050\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 81.7761 - val_loss: 22.3454 - lr: 0.0050\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 84.3951 - val_loss: 21.1361 - lr: 0.0050\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 79.2937 - val_loss: 20.1504 - lr: 0.0050\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 81.5482 - val_loss: 19.6010 - lr: 0.0050\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 78.9029 - val_loss: 19.7565 - lr: 0.0050\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 74.0320 - val_loss: 20.3527 - lr: 0.0050\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 72.0191 - val_loss: 21.1708 - lr: 0.0050\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 55.9946 - val_loss: 22.4982 - lr: 0.0050\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 69.7199 - val_loss: 24.4903 - lr: 0.0050\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 64.0300 - val_loss: 27.3631 - lr: 0.0050\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 45.5886 - val_loss: 29.8401 - lr: 0.0050\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 64.0752 - val_loss: 32.0759 - lr: 0.0050\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 48.1576 - val_loss: 33.9046 - lr: 0.0050\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 38.1045 - val_loss: 35.8757 - lr: 0.0050\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 47.4176 - val_loss: 38.3022 - lr: 0.0050\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 53.0008 - val_loss: 40.2856 - lr: 0.0050\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 36.7383 - val_loss: 41.9521 - lr: 0.0050\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 44.2763 - val_loss: 42.7810 - lr: 0.0050\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 39.3045 - val_loss: 41.3586 - lr: 0.0050\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 33.3038 - val_loss: 36.9427 - lr: 0.0050\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 34.4734 - val_loss: 32.3486 - lr: 0.0050\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 40.3074 - val_loss: 31.2661 - lr: 0.0050\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 36.5532 - val_loss: 31.7637 - lr: 0.0050\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 28.5472 - val_loss: 34.6683 - lr: 0.0050\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 18.4109 - val_loss: 38.0163 - lr: 0.0050\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 23.6670 - val_loss: 42.5774 - lr: 0.0050\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 22.1947 - val_loss: 49.6270 - lr: 0.0050\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 17.7616 - val_loss: 57.4318 - lr: 0.0050\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 21.9837 - val_loss: 66.3577 - lr: 0.0050\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 24.5308 - val_loss: 74.7871 - lr: 0.0050\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 12.6296 - val_loss: 79.4401 - lr: 0.0050\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 17.7683 - val_loss: 82.3917 - lr: 0.0050\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 13.2199 - val_loss: 82.0030 - lr: 0.0050\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 16.3262 - val_loss: 78.3523 - lr: 0.0050\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13.5698 - val_loss: 76.4736 - lr: 0.0050\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.6156 - val_loss: 73.6925 - lr: 0.0050\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 16.9245 - val_loss: 70.9196 - lr: 0.0050\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 14.8048 - val_loss: 68.6981 - lr: 0.0050\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10.2240 - val_loss: 66.2210 - lr: 0.0050\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 14.7940 - val_loss: 66.5976 - lr: 0.0050\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 12.3291 - val_loss: 67.4628 - lr: 0.0050\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.3108 - val_loss: 67.9841 - lr: 0.0050\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 22.1230 - val_loss: 68.2488 - lr: 0.0050\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.7470 - val_loss: 68.5500 - lr: 0.0050\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10.8400 - val_loss: 69.8267 - lr: 0.0050\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.8716 - val_loss: 70.9900 - lr: 0.0050\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 14.9752 - val_loss: 73.2891 - lr: 0.0050\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.1823 - val_loss: 76.2943 - lr: 0.0050\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 17.4215 - val_loss: 72.7403 - lr: 0.0050\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 10.5336 - val_loss: 67.4041 - lr: 0.0050\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 12.9156 - val_loss: 58.2723 - lr: 0.0050\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 19.6926 - val_loss: 53.9916 - lr: 0.0050\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.5449 - val_loss: 51.6818 - lr: 0.0050\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1108 - val_loss: 52.0863 - lr: 0.0050\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.8238 - val_loss: 52.6744 - lr: 0.0025\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.5956 - val_loss: 52.2589 - lr: 0.0025\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.4033 - val_loss: 52.0782 - lr: 0.0025\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 9.2066 - val_loss: 51.9426 - lr: 0.0025\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 16.1305 - val_loss: 53.9960 - lr: 0.0025\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 19.4520 - val_loss: 57.9472 - lr: 0.0025\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.8834 - val_loss: 63.0983 - lr: 0.0025\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 22.1198 - val_loss: 68.8328 - lr: 0.0025\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.9443 - val_loss: 70.2050 - lr: 0.0025\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 11.3019 - val_loss: 72.5676 - lr: 0.0025\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.3720 - val_loss: 75.4218 - lr: 0.0025\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10.5476 - val_loss: 77.3649 - lr: 0.0025\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.3384 - val_loss: 79.4785 - lr: 0.0025\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.3047 - val_loss: 81.5474 - lr: 0.0025\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.4683 - val_loss: 82.9098 - lr: 0.0025\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 11.7504 - val_loss: 88.0699 - lr: 0.0025\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 16.4111 - val_loss: 88.9251 - lr: 0.0025\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.4542 - val_loss: 88.0821 - lr: 0.0025\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10.8476 - val_loss: 86.6025 - lr: 0.0025\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 15.0495 - val_loss: 81.9250 - lr: 0.0025\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.2148 - val_loss: 72.4111 - lr: 0.0025\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.3496 - val_loss: 69.0714 - lr: 0.0025\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.6481 - val_loss: 66.4816 - lr: 0.0025\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.7132 - val_loss: 65.6406 - lr: 0.0025\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 11.0990 - val_loss: 65.3523 - lr: 0.0025\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 15.4318 - val_loss: 67.2846 - lr: 0.0025\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.9830 - val_loss: 69.0345 - lr: 0.0025\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 15.2674 - val_loss: 71.2650 - lr: 0.0025\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.4099 - val_loss: 74.1827 - lr: 0.0025\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.9706 - val_loss: 77.5502 - lr: 0.0025\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.9420 - val_loss: 81.2483 - lr: 0.0025\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4.1186 - val_loss: 85.2418 - lr: 0.0025\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.7112 - val_loss: 90.1589 - lr: 0.0025\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.9265 - val_loss: 94.3386 - lr: 0.0025\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7361 - val_loss: 95.8800 - lr: 0.0025\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.4611 - val_loss: 97.8919 - lr: 0.0025\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.0693 - val_loss: 98.3408 - lr: 0.0025\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.6885 - val_loss: 95.0537 - lr: 0.0025\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.3297 - val_loss: 91.5277 - lr: 0.0025\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.9559 - val_loss: 87.9442 - lr: 0.0025\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.6155 - val_loss: 84.5147 - lr: 0.0025\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.3440 - val_loss: 82.3776 - lr: 0.0025\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4024 - val_loss: 79.4622 - lr: 0.0025\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.3756 - val_loss: 77.7879 - lr: 0.0025\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.4501 - val_loss: 78.7439 - lr: 0.0025\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.9028 - val_loss: 79.1014 - lr: 0.0025\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.3669 - val_loss: 80.1585 - lr: 0.0025\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.5286 - val_loss: 80.4815 - lr: 0.0025\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.6538 - val_loss: 79.9838 - lr: 0.0025\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.1985 - val_loss: 83.6411 - lr: 0.0025\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 10.8877 - val_loss: 86.4808 - lr: 0.0012\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.4043 - val_loss: 89.4301 - lr: 0.0012\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.8889 - val_loss: 91.6781 - lr: 0.0012\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.7733 - val_loss: 93.4196 - lr: 0.0012\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 11.8958 - val_loss: 93.2880 - lr: 0.0012\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.8380 - val_loss: 92.7875 - lr: 0.0012\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.8545 - val_loss: 92.0812 - lr: 0.0012\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.4698 - val_loss: 92.7173 - lr: 0.0012\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.6060 - val_loss: 93.0366 - lr: 0.0012\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.0083 - val_loss: 94.6424 - lr: 0.0012\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0452 - val_loss: 96.1884 - lr: 0.0012\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.1262 - val_loss: 97.7009 - lr: 0.0012\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.3758 - val_loss: 99.3639 - lr: 0.0012\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 28.1303 - val_loss: 100.8976 - lr: 0.0012\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.2308 - val_loss: 102.4436 - lr: 0.0012\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.9187 - val_loss: 104.3986 - lr: 0.0012\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.7265 - val_loss: 106.0006 - lr: 0.0012\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.0103 - val_loss: 106.1401 - lr: 0.0012\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 10.6466 - val_loss: 105.4844 - lr: 0.0012\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.7938 - val_loss: 104.5289 - lr: 0.0012\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 11.4348 - val_loss: 103.6987 - lr: 0.0012\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.2702 - val_loss: 102.6283 - lr: 0.0012\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.4484 - val_loss: 101.8747 - lr: 0.0012\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.3770 - val_loss: 101.6617 - lr: 0.0012\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.9561 - val_loss: 101.2021 - lr: 0.0012\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.2928 - val_loss: 101.0420 - lr: 0.0012\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.0572 - val_loss: 101.2360 - lr: 0.0012\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.8545 - val_loss: 102.1019 - lr: 0.0012\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.0308 - val_loss: 102.1544 - lr: 0.0012\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7376 - val_loss: 101.6474 - lr: 0.0012\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 10.5854 - val_loss: 101.2928 - lr: 0.0012\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.0264 - val_loss: 101.6590 - lr: 0.0012\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.6663 - val_loss: 101.3449 - lr: 0.0012\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3783 - val_loss: 100.9169 - lr: 0.0012\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.1806 - val_loss: 100.7058 - lr: 0.0012\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2884 - val_loss: 100.7369 - lr: 0.0012\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.4898 - val_loss: 101.0064 - lr: 0.0012\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.2487 - val_loss: 100.5150 - lr: 0.0012\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.8402 - val_loss: 99.9059 - lr: 0.0012\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.3638 - val_loss: 99.7264 - lr: 0.0012\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.2926 - val_loss: 100.2588 - lr: 0.0012\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3668 - val_loss: 100.7865 - lr: 0.0012\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.4215 - val_loss: 102.3437 - lr: 0.0012\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7646 - val_loss: 104.5504 - lr: 0.0012\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.3886 - val_loss: 106.6992 - lr: 0.0012\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.0004 - val_loss: 108.6649 - lr: 0.0012\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2262 - val_loss: 109.7344 - lr: 0.0012\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.8308 - val_loss: 110.7666 - lr: 0.0012\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5005 - val_loss: 111.5813 - lr: 0.0012\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.0248 - val_loss: 112.6275 - lr: 0.0012\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.0942 - val_loss: 113.5992 - lr: 6.2500e-04\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.9928 - val_loss: 114.4050 - lr: 6.2500e-04\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.6071 - val_loss: 114.9026 - lr: 6.2500e-04\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7157 - val_loss: 115.0303 - lr: 6.2500e-04\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.1379 - val_loss: 114.9036 - lr: 6.2500e-04\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3917 - val_loss: 114.9365 - lr: 6.2500e-04\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.0479 - val_loss: 114.8644 - lr: 6.2500e-04\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.6600 - val_loss: 114.5731 - lr: 6.2500e-04\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7426 - val_loss: 114.4195 - lr: 6.2500e-04\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.8467 - val_loss: 114.3827 - lr: 6.2500e-04\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.3352 - val_loss: 114.0353 - lr: 6.2500e-04\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.0211 - val_loss: 113.9076 - lr: 6.2500e-04\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 7.0522 - val_loss: 113.3208 - lr: 6.2500e-04\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.9811 - val_loss: 113.9981 - lr: 6.2500e-04\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.3411 - val_loss: 114.1219 - lr: 6.2500e-04\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.9062 - val_loss: 114.0848 - lr: 6.2500e-04\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.6103 - val_loss: 114.4319 - lr: 6.2500e-04\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.7012 - val_loss: 114.8326 - lr: 6.2500e-04\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.8551 - val_loss: 114.4640 - lr: 6.2500e-04\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.4491 - val_loss: 114.4252 - lr: 6.2500e-04\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.3331 - val_loss: 114.1030 - lr: 6.2500e-04\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 11.3546 - val_loss: 114.2821 - lr: 6.2500e-04\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.2222 - val_loss: 113.9802 - lr: 6.2500e-04\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1054 - val_loss: 114.0512 - lr: 6.2500e-04\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.0944 - val_loss: 114.3467 - lr: 6.2500e-04\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.6136 - val_loss: 114.9028 - lr: 6.2500e-04\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.5665 - val_loss: 115.8489 - lr: 6.2500e-04\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.1797 - val_loss: 116.9383 - lr: 6.2500e-04\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1490 - val_loss: 118.1336 - lr: 6.2500e-04\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.4712 - val_loss: 119.0665 - lr: 6.2500e-04\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.1046 - val_loss: 120.5591 - lr: 6.2500e-04\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7233 - val_loss: 121.8398 - lr: 6.2500e-04\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.8723 - val_loss: 122.6003 - lr: 6.2500e-04\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.0171 - val_loss: 122.7454 - lr: 6.2500e-04\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 8.4909 - val_loss: 123.1613 - lr: 6.2500e-04\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.9376 - val_loss: 123.6633 - lr: 6.2500e-04\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.0603 - val_loss: 123.8766 - lr: 6.2500e-04\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.6919 - val_loss: 124.3628 - lr: 6.2500e-04\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.0677 - val_loss: 125.1124 - lr: 6.2500e-04\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.5426 - val_loss: 126.6561 - lr: 6.2500e-04\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.6779 - val_loss: 126.7827 - lr: 6.2500e-04\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.9875 - val_loss: 126.9545 - lr: 6.2500e-04\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.6443 - val_loss: 127.2808 - lr: 6.2500e-04\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.6578 - val_loss: 127.7200 - lr: 6.2500e-04\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.7693 - val_loss: 127.3859 - lr: 6.2500e-04\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.9155 - val_loss: 127.0643 - lr: 6.2500e-04\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.5156 - val_loss: 127.2193 - lr: 6.2500e-04\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.4160 - val_loss: 127.0689 - lr: 6.2500e-04\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.0315 - val_loss: 126.5305 - lr: 6.2500e-04\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.3299 - val_loss: 126.0660 - lr: 6.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 1/6 [00:51<04:19, 51.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 673.5446 - val_loss: 495.9292 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 667.4454 - val_loss: 494.1566 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 659.2734 - val_loss: 490.0960 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 659.6562 - val_loss: 486.0714 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 661.1597 - val_loss: 484.1804 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 664.5955 - val_loss: 484.3848 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 651.8609 - val_loss: 486.4997 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 648.3925 - val_loss: 486.9741 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 649.5768 - val_loss: 485.1676 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 644.3205 - val_loss: 481.4307 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 647.5021 - val_loss: 476.5838 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 641.4191 - val_loss: 473.3053 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 636.7366 - val_loss: 470.1581 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 639.9538 - val_loss: 464.1615 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 628.0394 - val_loss: 457.0297 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 629.1996 - val_loss: 447.4394 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 625.0958 - val_loss: 437.3173 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 621.8091 - val_loss: 428.0802 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 617.4546 - val_loss: 421.3629 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 616.2167 - val_loss: 414.2475 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 615.0362 - val_loss: 409.4862 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 609.8489 - val_loss: 404.8218 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 612.6341 - val_loss: 405.2438 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 603.0710 - val_loss: 405.3307 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 598.5922 - val_loss: 404.8850 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 600.7745 - val_loss: 400.6484 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 592.9134 - val_loss: 392.8990 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 593.0978 - val_loss: 383.2144 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 584.7294 - val_loss: 372.6352 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 579.6154 - val_loss: 360.3944 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 575.7726 - val_loss: 349.3763 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 574.2137 - val_loss: 342.0575 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 564.2914 - val_loss: 334.7311 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 558.3040 - val_loss: 330.4035 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 556.5071 - val_loss: 328.0838 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 551.6977 - val_loss: 330.6049 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 545.1082 - val_loss: 338.5435 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 534.5003 - val_loss: 348.7683 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 531.6129 - val_loss: 359.2730 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 530.2097 - val_loss: 372.3934 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 520.2757 - val_loss: 381.4945 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 513.9191 - val_loss: 382.7017 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 518.6285 - val_loss: 376.7108 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 502.0148 - val_loss: 362.2957 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 496.9840 - val_loss: 347.6479 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 491.7351 - val_loss: 327.4060 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 484.5792 - val_loss: 309.2809 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 479.3351 - val_loss: 282.8805 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 465.0982 - val_loss: 263.8160 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 458.1440 - val_loss: 252.2493 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 455.4038 - val_loss: 244.6134 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 452.3942 - val_loss: 241.7963 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 441.8603 - val_loss: 240.3374 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 430.8250 - val_loss: 235.3861 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 427.5419 - val_loss: 227.9395 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 419.2260 - val_loss: 220.7600 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 405.5894 - val_loss: 211.5247 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 401.7314 - val_loss: 204.0951 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 396.0334 - val_loss: 197.2291 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 384.3333 - val_loss: 193.9931 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 373.3355 - val_loss: 191.3660 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 364.6819 - val_loss: 189.8282 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 359.2594 - val_loss: 187.7293 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 354.6647 - val_loss: 182.4675 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 349.3444 - val_loss: 175.4152 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 332.7108 - val_loss: 164.7188 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 337.7952 - val_loss: 157.5551 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 323.6441 - val_loss: 153.5964 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 308.8307 - val_loss: 149.7745 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 303.3594 - val_loss: 143.3972 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 294.4934 - val_loss: 132.6140 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 292.1642 - val_loss: 125.7973 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 280.5556 - val_loss: 119.6858 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 267.3540 - val_loss: 114.0306 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 269.5519 - val_loss: 108.6687 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 265.5665 - val_loss: 103.8137 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 263.7829 - val_loss: 99.9657 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 245.8079 - val_loss: 95.3472 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 241.7817 - val_loss: 90.5921 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 232.1472 - val_loss: 85.7520 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 223.1110 - val_loss: 80.8788 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 213.1212 - val_loss: 75.2934 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 217.6578 - val_loss: 70.9546 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 201.2750 - val_loss: 66.7029 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 194.8414 - val_loss: 63.3655 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 191.9967 - val_loss: 59.4078 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 185.5734 - val_loss: 55.5092 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 174.2245 - val_loss: 52.3307 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 166.0719 - val_loss: 49.9099 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 161.6709 - val_loss: 48.2369 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 155.3420 - val_loss: 46.0320 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 148.4780 - val_loss: 43.6203 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 142.9954 - val_loss: 40.6670 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 147.6126 - val_loss: 37.3960 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 143.5065 - val_loss: 34.1691 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 130.6368 - val_loss: 30.5658 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 122.1800 - val_loss: 27.6783 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 117.8350 - val_loss: 25.2740 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 115.7962 - val_loss: 23.2639 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 122.6367 - val_loss: 22.0505 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 109.8013 - val_loss: 21.5910 - lr: 0.0050\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 105.2105 - val_loss: 21.8435 - lr: 0.0050\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 94.5986 - val_loss: 22.6626 - lr: 0.0050\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 90.0223 - val_loss: 23.4751 - lr: 0.0050\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 86.1612 - val_loss: 24.2116 - lr: 0.0050\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 81.0107 - val_loss: 24.9309 - lr: 0.0050\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 81.3640 - val_loss: 25.7800 - lr: 0.0050\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 74.3064 - val_loss: 26.7988 - lr: 0.0050\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 72.7003 - val_loss: 27.7870 - lr: 0.0050\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 63.4456 - val_loss: 28.6652 - lr: 0.0050\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 66.7401 - val_loss: 29.6202 - lr: 0.0050\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 69.9802 - val_loss: 30.1648 - lr: 0.0050\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 60.2552 - val_loss: 30.3669 - lr: 0.0050\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 51.5990 - val_loss: 30.5747 - lr: 0.0050\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 50.4716 - val_loss: 30.9750 - lr: 0.0050\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 49.5081 - val_loss: 31.6479 - lr: 0.0050\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 45.3490 - val_loss: 34.1768 - lr: 0.0050\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 40.7231 - val_loss: 39.3201 - lr: 0.0050\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 45.1611 - val_loss: 44.1390 - lr: 0.0050\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 39.4784 - val_loss: 47.3960 - lr: 0.0050\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 33.7308 - val_loss: 51.5901 - lr: 0.0050\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 45.2307 - val_loss: 54.3776 - lr: 0.0050\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 37.0924 - val_loss: 56.3508 - lr: 0.0050\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 28.8217 - val_loss: 56.8857 - lr: 0.0050\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 24.9234 - val_loss: 59.3455 - lr: 0.0050\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 25.8637 - val_loss: 63.0388 - lr: 0.0050\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 27.6596 - val_loss: 69.3574 - lr: 0.0050\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 30.7420 - val_loss: 73.5032 - lr: 0.0050\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 22.3137 - val_loss: 75.3040 - lr: 0.0050\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 23.7599 - val_loss: 76.2795 - lr: 0.0050\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 32.9967 - val_loss: 76.0494 - lr: 0.0050\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 23.7755 - val_loss: 75.4725 - lr: 0.0050\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 25.7320 - val_loss: 73.5374 - lr: 0.0050\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 16.9268 - val_loss: 71.7051 - lr: 0.0050\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 24.0120 - val_loss: 72.3444 - lr: 0.0050\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 22.1526 - val_loss: 74.0084 - lr: 0.0050\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 16.7069 - val_loss: 76.8741 - lr: 0.0050\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 14.8531 - val_loss: 81.6409 - lr: 0.0050\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 18.3382 - val_loss: 86.8774 - lr: 0.0050\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 23.3930 - val_loss: 89.4733 - lr: 0.0050\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 14.6371 - val_loss: 92.5428 - lr: 0.0050\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 11.8907 - val_loss: 94.5286 - lr: 0.0050\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 11.4803 - val_loss: 97.6103 - lr: 0.0050\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 12.8169 - val_loss: 101.6606 - lr: 0.0050\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.6355 - val_loss: 102.6093 - lr: 0.0050\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 15.9896 - val_loss: 102.5147 - lr: 0.0050\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 15.4996 - val_loss: 101.7704 - lr: 0.0050\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14.7664 - val_loss: 102.2112 - lr: 0.0050\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 12.4845 - val_loss: 105.0516 - lr: 0.0050\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.6020 - val_loss: 105.9066 - lr: 0.0050\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 12.2127 - val_loss: 104.2564 - lr: 0.0050\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.7723 - val_loss: 104.2211 - lr: 0.0025\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 13.3395 - val_loss: 102.2875 - lr: 0.0025\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.1295 - val_loss: 103.5686 - lr: 0.0025\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9961 - val_loss: 104.8852 - lr: 0.0025\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 16.0723 - val_loss: 106.8543 - lr: 0.0025\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.9561 - val_loss: 109.3739 - lr: 0.0025\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 12.9596 - val_loss: 111.4249 - lr: 0.0025\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.2237 - val_loss: 113.0128 - lr: 0.0025\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10.0275 - val_loss: 114.6696 - lr: 0.0025\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 13.4604 - val_loss: 117.7365 - lr: 0.0025\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 15.5240 - val_loss: 121.1166 - lr: 0.0025\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 14.2196 - val_loss: 125.5598 - lr: 0.0025\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 10.7730 - val_loss: 129.3428 - lr: 0.0025\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.7426 - val_loss: 133.5251 - lr: 0.0025\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 11.0040 - val_loss: 138.5471 - lr: 0.0025\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.8913 - val_loss: 143.1533 - lr: 0.0025\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 8.3425 - val_loss: 147.7777 - lr: 0.0025\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.6427 - val_loss: 151.9140 - lr: 0.0025\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.3297 - val_loss: 154.9752 - lr: 0.0025\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.3567 - val_loss: 157.5184 - lr: 0.0025\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.4544 - val_loss: 158.4849 - lr: 0.0025\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 11.4139 - val_loss: 158.6813 - lr: 0.0025\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 12.7723 - val_loss: 162.0337 - lr: 0.0025\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 10.0637 - val_loss: 163.5208 - lr: 0.0025\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.7202 - val_loss: 164.2354 - lr: 0.0025\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.8438 - val_loss: 164.2668 - lr: 0.0025\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.4742 - val_loss: 165.2669 - lr: 0.0025\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13.4852 - val_loss: 165.8309 - lr: 0.0025\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.0470 - val_loss: 164.9481 - lr: 0.0025\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11.8250 - val_loss: 163.6906 - lr: 0.0025\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 9.5732 - val_loss: 163.2378 - lr: 0.0025\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.7174 - val_loss: 163.1226 - lr: 0.0025\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.5394 - val_loss: 162.5489 - lr: 0.0025\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.9967 - val_loss: 163.0254 - lr: 0.0025\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 15.4005 - val_loss: 161.4086 - lr: 0.0025\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.5611 - val_loss: 161.2015 - lr: 0.0025\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 11.4662 - val_loss: 161.9925 - lr: 0.0025\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10.1830 - val_loss: 161.7513 - lr: 0.0025\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.7081 - val_loss: 159.9174 - lr: 0.0025\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.9593 - val_loss: 157.3779 - lr: 0.0025\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.0375 - val_loss: 155.2766 - lr: 0.0025\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.3506 - val_loss: 151.9778 - lr: 0.0025\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.7372 - val_loss: 149.2312 - lr: 0.0025\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.5959 - val_loss: 147.9278 - lr: 0.0025\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 8.1226 - val_loss: 145.7982 - lr: 0.0025\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.9093 - val_loss: 142.7708 - lr: 0.0025\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.6956 - val_loss: 141.4893 - lr: 0.0025\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 12.0839 - val_loss: 143.2484 - lr: 0.0025\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 15.6679 - val_loss: 146.6088 - lr: 0.0025\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 10.8515 - val_loss: 149.3808 - lr: 0.0025\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 10.2181 - val_loss: 151.3080 - lr: 0.0012\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.3370 - val_loss: 153.2007 - lr: 0.0012\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.3600 - val_loss: 154.6816 - lr: 0.0012\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 11.2320 - val_loss: 156.2749 - lr: 0.0012\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.1870 - val_loss: 157.5206 - lr: 0.0012\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 11.6846 - val_loss: 158.4491 - lr: 0.0012\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11.1216 - val_loss: 158.9536 - lr: 0.0012\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.3364 - val_loss: 158.6050 - lr: 0.0012\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.3752 - val_loss: 158.3659 - lr: 0.0012\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 10.4093 - val_loss: 158.3934 - lr: 0.0012\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.0091 - val_loss: 156.7197 - lr: 0.0012\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.7075 - val_loss: 154.4088 - lr: 0.0012\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.5029 - val_loss: 152.6847 - lr: 0.0012\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 10.7205 - val_loss: 151.8558 - lr: 0.0012\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.1026 - val_loss: 152.4363 - lr: 0.0012\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.1248 - val_loss: 153.4097 - lr: 0.0012\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 7.7638 - val_loss: 154.8286 - lr: 0.0012\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.3635 - val_loss: 156.2092 - lr: 0.0012\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 7.0705 - val_loss: 158.4770 - lr: 0.0012\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.1449 - val_loss: 161.5563 - lr: 0.0012\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.2652 - val_loss: 164.3994 - lr: 0.0012\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.2578 - val_loss: 166.1596 - lr: 0.0012\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.0247 - val_loss: 166.9386 - lr: 0.0012\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.5153 - val_loss: 166.9274 - lr: 0.0012\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.4690 - val_loss: 167.6199 - lr: 0.0012\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.7930 - val_loss: 168.6523 - lr: 0.0012\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.0219 - val_loss: 169.7444 - lr: 0.0012\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.0859 - val_loss: 171.0730 - lr: 0.0012\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.9182 - val_loss: 172.3467 - lr: 0.0012\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.5197 - val_loss: 173.9783 - lr: 0.0012\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 10.2128 - val_loss: 175.0825 - lr: 0.0012\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3941 - val_loss: 176.2650 - lr: 0.0012\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.1051 - val_loss: 176.9618 - lr: 0.0012\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.4612 - val_loss: 178.2245 - lr: 0.0012\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.3613 - val_loss: 179.3854 - lr: 0.0012\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.8495 - val_loss: 180.5939 - lr: 0.0012\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.0644 - val_loss: 182.3994 - lr: 0.0012\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.4568 - val_loss: 184.2350 - lr: 0.0012\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.7260 - val_loss: 185.6053 - lr: 0.0012\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.3378 - val_loss: 186.6753 - lr: 0.0012\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.6396 - val_loss: 187.1496 - lr: 0.0012\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 13.4929 - val_loss: 187.4133 - lr: 0.0012\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.4741 - val_loss: 187.6164 - lr: 0.0012\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.1736 - val_loss: 188.3756 - lr: 0.0012\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.7109 - val_loss: 189.4165 - lr: 0.0012\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.7407 - val_loss: 190.7372 - lr: 0.0012\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.2838 - val_loss: 192.1153 - lr: 0.0012\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 11.0404 - val_loss: 193.1702 - lr: 0.0012\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6.6925 - val_loss: 193.9823 - lr: 0.0012\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.9062 - val_loss: 194.5068 - lr: 0.0012\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.3102 - val_loss: 195.1035 - lr: 6.2500e-04\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.5131 - val_loss: 195.5049 - lr: 6.2500e-04\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5.0081 - val_loss: 196.0090 - lr: 6.2500e-04\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.0758 - val_loss: 196.0513 - lr: 6.2500e-04\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 11.5196 - val_loss: 195.9139 - lr: 6.2500e-04\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7955 - val_loss: 195.8611 - lr: 6.2500e-04\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.1139 - val_loss: 195.7440 - lr: 6.2500e-04\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.4019 - val_loss: 195.4384 - lr: 6.2500e-04\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 10.8206 - val_loss: 195.3147 - lr: 6.2500e-04\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.7059 - val_loss: 195.2763 - lr: 6.2500e-04\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 10.6432 - val_loss: 195.2736 - lr: 6.2500e-04\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.3569 - val_loss: 195.4747 - lr: 6.2500e-04\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.3950 - val_loss: 195.5514 - lr: 6.2500e-04\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 14.8984 - val_loss: 195.6233 - lr: 6.2500e-04\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.6596 - val_loss: 195.4086 - lr: 6.2500e-04\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 12.9879 - val_loss: 195.4722 - lr: 6.2500e-04\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.3002 - val_loss: 195.3344 - lr: 6.2500e-04\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.6690 - val_loss: 194.9777 - lr: 6.2500e-04\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.3391 - val_loss: 194.9899 - lr: 6.2500e-04\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.2476 - val_loss: 194.5759 - lr: 6.2500e-04\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.1870 - val_loss: 194.6279 - lr: 6.2500e-04\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.3459 - val_loss: 194.3960 - lr: 6.2500e-04\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.4866 - val_loss: 194.2780 - lr: 6.2500e-04\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.9001 - val_loss: 193.8785 - lr: 6.2500e-04\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3690 - val_loss: 193.7538 - lr: 6.2500e-04\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.5847 - val_loss: 192.9772 - lr: 6.2500e-04\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.7852 - val_loss: 192.4514 - lr: 6.2500e-04\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.0634 - val_loss: 192.8502 - lr: 6.2500e-04\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 11.2058 - val_loss: 193.3630 - lr: 6.2500e-04\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7374 - val_loss: 192.8638 - lr: 6.2500e-04\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.2683 - val_loss: 192.5661 - lr: 6.2500e-04\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.4658 - val_loss: 192.2402 - lr: 6.2500e-04\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.8718 - val_loss: 191.8567 - lr: 6.2500e-04\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.6160 - val_loss: 191.8121 - lr: 6.2500e-04\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.1034 - val_loss: 192.6893 - lr: 6.2500e-04\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.9542 - val_loss: 194.4139 - lr: 6.2500e-04\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8.4263 - val_loss: 197.0895 - lr: 6.2500e-04\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.2070 - val_loss: 199.6224 - lr: 6.2500e-04\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.9037 - val_loss: 201.5220 - lr: 6.2500e-04\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.0344 - val_loss: 203.1567 - lr: 6.2500e-04\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 10.9700 - val_loss: 203.5915 - lr: 6.2500e-04\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.2914 - val_loss: 203.8824 - lr: 6.2500e-04\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.6693 - val_loss: 203.9465 - lr: 6.2500e-04\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.9545 - val_loss: 203.9241 - lr: 6.2500e-04\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.1090 - val_loss: 203.3890 - lr: 6.2500e-04\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.8979 - val_loss: 202.5521 - lr: 6.2500e-04\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5747 - val_loss: 202.0013 - lr: 6.2500e-04\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.1359 - val_loss: 201.3246 - lr: 6.2500e-04\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.3963 - val_loss: 200.9594 - lr: 6.2500e-04\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.6019 - val_loss: 200.7938 - lr: 6.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 2/6 [01:40<03:20, 50.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 6s 1s/step - loss: 614.2626 - val_loss: 374.6882 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 609.0680 - val_loss: 371.5643 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 601.7855 - val_loss: 373.4449 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 605.4660 - val_loss: 375.3599 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 597.0208 - val_loss: 373.9862 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 602.0615 - val_loss: 366.2267 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 595.1482 - val_loss: 360.3867 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 590.2798 - val_loss: 356.3880 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 580.6188 - val_loss: 353.6281 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 578.2518 - val_loss: 351.7064 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 578.3206 - val_loss: 350.5388 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 569.4528 - val_loss: 347.9067 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 564.1836 - val_loss: 343.7061 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 555.6282 - val_loss: 336.0377 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 548.0222 - val_loss: 330.8207 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 537.8801 - val_loss: 320.4497 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 535.0096 - val_loss: 310.0328 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 523.2263 - val_loss: 296.5043 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 518.7096 - val_loss: 295.2327 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 504.7028 - val_loss: 299.7710 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 497.4971 - val_loss: 304.2630 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 494.8872 - val_loss: 303.3305 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 482.5267 - val_loss: 279.4392 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 462.3555 - val_loss: 262.7888 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 454.4170 - val_loss: 246.6197 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 449.3094 - val_loss: 224.3745 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 430.1057 - val_loss: 203.3560 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 414.1361 - val_loss: 187.2885 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 404.3249 - val_loss: 173.9464 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 390.6048 - val_loss: 159.1199 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 371.0984 - val_loss: 144.3450 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 353.9279 - val_loss: 130.8912 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 345.9420 - val_loss: 112.4143 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 322.3051 - val_loss: 96.1199 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 313.7932 - val_loss: 86.1465 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 298.6530 - val_loss: 76.5607 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 275.6810 - val_loss: 67.4407 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 273.6835 - val_loss: 59.3803 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 251.9771 - val_loss: 50.2071 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 241.5776 - val_loss: 45.7305 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 230.2892 - val_loss: 45.6848 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 219.3596 - val_loss: 43.7121 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 203.6074 - val_loss: 34.8582 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 185.0585 - val_loss: 25.9699 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 167.8440 - val_loss: 22.0202 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 166.1879 - val_loss: 22.5192 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 145.7936 - val_loss: 23.4326 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 139.5694 - val_loss: 20.9633 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 131.9050 - val_loss: 15.6798 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 119.4693 - val_loss: 14.2430 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 113.0080 - val_loss: 14.3874 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 108.1657 - val_loss: 15.3544 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 89.2002 - val_loss: 17.8160 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 86.9391 - val_loss: 20.6983 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 83.1147 - val_loss: 21.7032 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 71.4906 - val_loss: 22.5450 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 69.5802 - val_loss: 23.1948 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 63.4898 - val_loss: 24.7377 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 65.1077 - val_loss: 25.8140 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 62.3175 - val_loss: 30.1348 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 51.1428 - val_loss: 38.9557 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 48.2264 - val_loss: 47.8877 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 44.1868 - val_loss: 48.0505 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 40.5971 - val_loss: 33.5434 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 43.8616 - val_loss: 21.7813 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 31.9827 - val_loss: 18.8357 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 45.1604 - val_loss: 19.3435 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 34.8358 - val_loss: 18.5963 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 30.3210 - val_loss: 17.8540 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 35.6148 - val_loss: 17.5329 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 28.8373 - val_loss: 17.6906 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 31.4413 - val_loss: 25.1388 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 28.0872 - val_loss: 73.6667 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 31.7507 - val_loss: 93.6895 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 36.3316 - val_loss: 105.4191 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 29.6406 - val_loss: 112.3561 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 32.9594 - val_loss: 120.3473 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 30.7493 - val_loss: 126.1537 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 30.2910 - val_loss: 128.6226 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 28.1005 - val_loss: 140.4628 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 25.0896 - val_loss: 151.2586 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 29.2007 - val_loss: 156.6942 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 33.0340 - val_loss: 162.8096 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 27.9656 - val_loss: 182.3024 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 30.4627 - val_loss: 186.7427 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 33.5763 - val_loss: 174.8549 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 34.5335 - val_loss: 170.0196 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 33.8559 - val_loss: 139.9347 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 32.1597 - val_loss: 104.7260 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 39.6729 - val_loss: 97.6588 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 30.6617 - val_loss: 101.4488 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 38.8027 - val_loss: 107.9974 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 31.1516 - val_loss: 114.6013 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 29.0237 - val_loss: 136.2677 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 29.3399 - val_loss: 145.1512 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 28.6294 - val_loss: 128.0355 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 29.1990 - val_loss: 89.9734 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 31.8198 - val_loss: 70.1185 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 24.7063 - val_loss: 56.1181 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 36.2237 - val_loss: 50.9023 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 31.2483 - val_loss: 48.9669 - lr: 0.0025\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 24.3682 - val_loss: 46.7845 - lr: 0.0025\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 21.3725 - val_loss: 46.4882 - lr: 0.0025\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 37.0396 - val_loss: 48.2081 - lr: 0.0025\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 27.6038 - val_loss: 51.0946 - lr: 0.0025\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 29.2324 - val_loss: 53.3295 - lr: 0.0025\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 26.5789 - val_loss: 54.5644 - lr: 0.0025\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 28.7969 - val_loss: 55.6264 - lr: 0.0025\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 32.4084 - val_loss: 57.5241 - lr: 0.0025\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 26.3053 - val_loss: 59.4033 - lr: 0.0025\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 28.7497 - val_loss: 62.4907 - lr: 0.0025\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 33.0490 - val_loss: 64.7331 - lr: 0.0025\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 23.7937 - val_loss: 67.0100 - lr: 0.0025\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 23.3385 - val_loss: 69.3699 - lr: 0.0025\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 32.6987 - val_loss: 72.3572 - lr: 0.0025\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 30.1262 - val_loss: 77.1797 - lr: 0.0025\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 21.2597 - val_loss: 92.7821 - lr: 0.0025\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 24.2160 - val_loss: 118.9059 - lr: 0.0025\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 30.0956 - val_loss: 172.5076 - lr: 0.0025\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 22.9964 - val_loss: 200.8128 - lr: 0.0025\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 27.7158 - val_loss: 217.2564 - lr: 0.0025\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 35.8475 - val_loss: 231.4523 - lr: 0.0025\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 28.2995 - val_loss: 238.4141 - lr: 0.0025\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 19.5750 - val_loss: 240.9451 - lr: 0.0025\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 30.7398 - val_loss: 242.6605 - lr: 0.0025\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 25.8514 - val_loss: 240.5335 - lr: 0.0025\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 25.3109 - val_loss: 237.3018 - lr: 0.0025\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 21.6190 - val_loss: 231.1971 - lr: 0.0025\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 21.0918 - val_loss: 224.4932 - lr: 0.0025\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 20.8006 - val_loss: 217.5129 - lr: 0.0025\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 23.1822 - val_loss: 207.6390 - lr: 0.0025\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 22.1608 - val_loss: 195.6080 - lr: 0.0025\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.3137 - val_loss: 187.9612 - lr: 0.0025\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 25.3873 - val_loss: 179.8295 - lr: 0.0025\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 25.9769 - val_loss: 171.7089 - lr: 0.0025\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 24.9524 - val_loss: 162.3089 - lr: 0.0025\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 26.9734 - val_loss: 155.4557 - lr: 0.0025\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 155ms/step - loss: 26.0472 - val_loss: 149.0285 - lr: 0.0025\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 19.1190 - val_loss: 144.0280 - lr: 0.0025\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 21.8851 - val_loss: 137.6211 - lr: 0.0025\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 26.7464 - val_loss: 128.8406 - lr: 0.0025\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 24.1734 - val_loss: 127.0920 - lr: 0.0025\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.2157 - val_loss: 129.9079 - lr: 0.0025\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 26.6838 - val_loss: 135.7683 - lr: 0.0025\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 21.5432 - val_loss: 144.6206 - lr: 0.0025\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 23.5144 - val_loss: 150.2632 - lr: 0.0025\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 20.1219 - val_loss: 150.9685 - lr: 0.0025\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.4411 - val_loss: 150.7478 - lr: 0.0025\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 25.9417 - val_loss: 147.2945 - lr: 0.0025\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 33.3859 - val_loss: 148.0758 - lr: 0.0025\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 24.3885 - val_loss: 145.4223 - lr: 0.0012\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 21.3587 - val_loss: 150.0261 - lr: 0.0012\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 23.4400 - val_loss: 161.9316 - lr: 0.0012\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 23.7436 - val_loss: 170.2139 - lr: 0.0012\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 23.9062 - val_loss: 173.3471 - lr: 0.0012\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 21.1412 - val_loss: 173.5813 - lr: 0.0012\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 23.8596 - val_loss: 171.9140 - lr: 0.0012\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 27.1653 - val_loss: 170.2666 - lr: 0.0012\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 18.5398 - val_loss: 171.1085 - lr: 0.0012\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 23.4057 - val_loss: 171.4480 - lr: 0.0012\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.2124 - val_loss: 170.9925 - lr: 0.0012\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 25.5388 - val_loss: 172.1270 - lr: 0.0012\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 20.3891 - val_loss: 170.7396 - lr: 0.0012\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 28.0968 - val_loss: 172.7079 - lr: 0.0012\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 21.4574 - val_loss: 178.0163 - lr: 0.0012\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 20.5537 - val_loss: 181.2015 - lr: 0.0012\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 21.8131 - val_loss: 184.8826 - lr: 0.0012\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 24.3955 - val_loss: 186.0107 - lr: 0.0012\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.8856 - val_loss: 187.3056 - lr: 0.0012\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 27.7120 - val_loss: 189.8347 - lr: 0.0012\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 26.1398 - val_loss: 193.9490 - lr: 0.0012\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 19.5726 - val_loss: 194.1301 - lr: 0.0012\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 23.4563 - val_loss: 191.2306 - lr: 0.0012\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 21.8890 - val_loss: 188.7004 - lr: 0.0012\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 22.4328 - val_loss: 186.4776 - lr: 0.0012\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 24.9420 - val_loss: 185.5160 - lr: 0.0012\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 25.5174 - val_loss: 183.2538 - lr: 0.0012\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 22.7926 - val_loss: 184.8946 - lr: 0.0012\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 23.0911 - val_loss: 187.2609 - lr: 0.0012\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 19.7102 - val_loss: 195.6444 - lr: 0.0012\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.5400 - val_loss: 203.9915 - lr: 0.0012\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 24.3140 - val_loss: 208.9816 - lr: 0.0012\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 24.0973 - val_loss: 214.2064 - lr: 0.0012\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 22.6859 - val_loss: 217.4903 - lr: 0.0012\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 20.2688 - val_loss: 223.5200 - lr: 0.0012\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 20.3069 - val_loss: 228.5104 - lr: 0.0012\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 17.3385 - val_loss: 232.7076 - lr: 0.0012\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 20.1252 - val_loss: 234.9162 - lr: 0.0012\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 22.1847 - val_loss: 238.2450 - lr: 0.0012\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.9464 - val_loss: 241.5099 - lr: 0.0012\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 23.7743 - val_loss: 243.8757 - lr: 0.0012\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 21.3598 - val_loss: 242.6837 - lr: 0.0012\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.8085 - val_loss: 240.3508 - lr: 0.0012\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 22.4917 - val_loss: 238.7679 - lr: 0.0012\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.6443 - val_loss: 240.1602 - lr: 0.0012\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 19.5107 - val_loss: 242.1799 - lr: 0.0012\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.2411 - val_loss: 245.2273 - lr: 0.0012\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.4002 - val_loss: 249.7927 - lr: 0.0012\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 31.6996 - val_loss: 252.5167 - lr: 0.0012\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 19.1833 - val_loss: 256.2049 - lr: 0.0012\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 23.7080 - val_loss: 258.1093 - lr: 6.2500e-04\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 23.2280 - val_loss: 261.0874 - lr: 6.2500e-04\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 22.4756 - val_loss: 262.5223 - lr: 6.2500e-04\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 20.1411 - val_loss: 262.7397 - lr: 6.2500e-04\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.4983 - val_loss: 264.3264 - lr: 6.2500e-04\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 23.1653 - val_loss: 266.5420 - lr: 6.2500e-04\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.9278 - val_loss: 265.7065 - lr: 6.2500e-04\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 21.1820 - val_loss: 263.8882 - lr: 6.2500e-04\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 22.7958 - val_loss: 262.8940 - lr: 6.2500e-04\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 19.9943 - val_loss: 260.6172 - lr: 6.2500e-04\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 19.6259 - val_loss: 262.1430 - lr: 6.2500e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 20.0789 - val_loss: 262.5293 - lr: 6.2500e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 20.9292 - val_loss: 263.6776 - lr: 6.2500e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 19.4755 - val_loss: 264.2405 - lr: 6.2500e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 23.6096 - val_loss: 264.9346 - lr: 6.2500e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 22.3512 - val_loss: 263.8311 - lr: 6.2500e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 19.5346 - val_loss: 261.7289 - lr: 6.2500e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 19.5466 - val_loss: 260.3633 - lr: 6.2500e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 22.0360 - val_loss: 258.0288 - lr: 6.2500e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.3272 - val_loss: 257.8560 - lr: 6.2500e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 17.8594 - val_loss: 256.4976 - lr: 6.2500e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 23.2109 - val_loss: 254.6976 - lr: 6.2500e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 23.7241 - val_loss: 256.0246 - lr: 6.2500e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 18.7105 - val_loss: 254.9382 - lr: 6.2500e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 22.3094 - val_loss: 254.3246 - lr: 6.2500e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 18.8508 - val_loss: 254.1956 - lr: 6.2500e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 20.4239 - val_loss: 256.6407 - lr: 6.2500e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 24.4912 - val_loss: 259.3409 - lr: 6.2500e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 18.5149 - val_loss: 261.3408 - lr: 6.2500e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.1741 - val_loss: 265.0600 - lr: 6.2500e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 19.8970 - val_loss: 268.2770 - lr: 6.2500e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.2507 - val_loss: 271.6117 - lr: 6.2500e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 21.7450 - val_loss: 274.2347 - lr: 6.2500e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 19.2089 - val_loss: 274.5814 - lr: 6.2500e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 18.8938 - val_loss: 277.1643 - lr: 6.2500e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 22.0986 - val_loss: 277.7204 - lr: 6.2500e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 20.7291 - val_loss: 280.0480 - lr: 6.2500e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 23.0391 - val_loss: 280.0607 - lr: 6.2500e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.0403 - val_loss: 282.1636 - lr: 6.2500e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 23.4065 - val_loss: 283.7906 - lr: 6.2500e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 22.7226 - val_loss: 284.5364 - lr: 6.2500e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.1585 - val_loss: 285.5829 - lr: 6.2500e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 22.7400 - val_loss: 285.3598 - lr: 6.2500e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.1441 - val_loss: 286.9902 - lr: 6.2500e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 19.8800 - val_loss: 286.8557 - lr: 6.2500e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 20.2606 - val_loss: 289.7451 - lr: 6.2500e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 19.0038 - val_loss: 292.3990 - lr: 6.2500e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 18.1025 - val_loss: 296.1547 - lr: 6.2500e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.8825 - val_loss: 301.8487 - lr: 6.2500e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 21.8712 - val_loss: 305.4357 - lr: 6.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 3/6 [02:12<02:04, 41.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 6s 1s/step - loss: 555.7705 - val_loss: 514.7438 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 551.2147 - val_loss: 519.0229 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 548.2591 - val_loss: 519.1400 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 541.6402 - val_loss: 517.2895 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 540.6018 - val_loss: 513.5291 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 538.0211 - val_loss: 506.7350 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 531.2726 - val_loss: 500.9480 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 526.5870 - val_loss: 491.1750 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 527.1469 - val_loss: 479.6104 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 518.7112 - val_loss: 472.4584 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 512.5405 - val_loss: 469.6109 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 505.5032 - val_loss: 467.2540 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 500.5395 - val_loss: 471.3428 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 491.8712 - val_loss: 479.5711 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 489.9794 - val_loss: 479.0797 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 477.8875 - val_loss: 474.6005 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 474.5652 - val_loss: 465.3377 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 467.0865 - val_loss: 447.5360 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 450.2069 - val_loss: 428.9164 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 445.5804 - val_loss: 413.3804 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 434.3597 - val_loss: 403.1513 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 422.3043 - val_loss: 393.6027 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 412.7661 - val_loss: 384.3380 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 400.0856 - val_loss: 371.9514 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 392.1580 - val_loss: 364.6274 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 376.1931 - val_loss: 349.9633 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 365.9781 - val_loss: 338.4844 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 349.5172 - val_loss: 334.3602 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 335.4724 - val_loss: 336.0267 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 320.4873 - val_loss: 331.3652 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 310.1043 - val_loss: 319.9701 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 290.5704 - val_loss: 306.7949 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 281.7165 - val_loss: 292.5384 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 269.2058 - val_loss: 277.6668 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 256.0532 - val_loss: 261.0771 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 242.6403 - val_loss: 243.4282 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 231.3132 - val_loss: 222.3294 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 211.5381 - val_loss: 201.6944 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 200.0801 - val_loss: 180.0866 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 196.6163 - val_loss: 181.2949 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 180.0461 - val_loss: 177.6064 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 168.2637 - val_loss: 163.2024 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 152.3029 - val_loss: 145.9596 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 139.1331 - val_loss: 133.1529 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 131.9271 - val_loss: 124.7075 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 119.5007 - val_loss: 120.8153 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 115.2127 - val_loss: 117.7248 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 108.8791 - val_loss: 112.3988 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 105.3626 - val_loss: 107.1808 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 95.9266 - val_loss: 103.9725 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 80.5109 - val_loss: 99.4733 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 75.2109 - val_loss: 91.3048 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 73.1454 - val_loss: 82.9299 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 68.6622 - val_loss: 73.3102 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 55.0541 - val_loss: 69.6338 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 55.5222 - val_loss: 66.6324 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 54.6616 - val_loss: 71.6485 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 46.4535 - val_loss: 73.2786 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 42.8232 - val_loss: 77.2159 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 39.4813 - val_loss: 83.6721 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 32.9232 - val_loss: 91.2052 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 27.2083 - val_loss: 95.6265 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 37.9202 - val_loss: 86.1332 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 32.2509 - val_loss: 56.3692 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 29.5303 - val_loss: 42.7449 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 26.1083 - val_loss: 35.1317 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 31.7869 - val_loss: 34.6792 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 22.0520 - val_loss: 35.6152 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 24.2413 - val_loss: 36.4200 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 25.2659 - val_loss: 38.9373 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 22.7062 - val_loss: 40.2953 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 25.6100 - val_loss: 46.8421 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.1149 - val_loss: 67.7157 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 21.8821 - val_loss: 87.0643 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 22.4190 - val_loss: 91.0296 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 20.3628 - val_loss: 100.0089 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 26.2547 - val_loss: 108.9668 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 26.8031 - val_loss: 96.6311 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 24.0108 - val_loss: 80.3767 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 23.8379 - val_loss: 73.6070 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 27.2343 - val_loss: 68.6259 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 21.2195 - val_loss: 60.2153 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 23.9613 - val_loss: 54.2739 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 20.9620 - val_loss: 48.3050 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 25.9879 - val_loss: 38.4470 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 26.4049 - val_loss: 36.5411 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 23.6789 - val_loss: 35.4510 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.0499 - val_loss: 35.0834 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 22.6397 - val_loss: 35.3822 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 21.1822 - val_loss: 35.7610 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.5628 - val_loss: 36.1803 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 17.9739 - val_loss: 37.2678 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 24.5243 - val_loss: 41.0703 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 25.6335 - val_loss: 44.5039 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 24.7314 - val_loss: 47.1781 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.1648 - val_loss: 45.9300 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.6359 - val_loss: 42.9661 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.1854 - val_loss: 41.2393 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 21.4944 - val_loss: 39.9081 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 20.5825 - val_loss: 40.6599 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 18.4103 - val_loss: 41.8037 - lr: 0.0050\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.7610 - val_loss: 42.8837 - lr: 0.0050\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.3824 - val_loss: 42.7165 - lr: 0.0050\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 18.2356 - val_loss: 41.7013 - lr: 0.0050\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 23.0942 - val_loss: 40.4188 - lr: 0.0050\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 20.2722 - val_loss: 39.6429 - lr: 0.0050\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.1208 - val_loss: 40.7233 - lr: 0.0050\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 20.1806 - val_loss: 44.6479 - lr: 0.0050\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.7168 - val_loss: 51.4351 - lr: 0.0050\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 19.7326 - val_loss: 58.2007 - lr: 0.0050\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 22.5186 - val_loss: 61.7660 - lr: 0.0050\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 25.0333 - val_loss: 63.6790 - lr: 0.0050\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 20.7518 - val_loss: 61.6537 - lr: 0.0050\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 18.8914 - val_loss: 60.7825 - lr: 0.0050\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.6398 - val_loss: 62.3543 - lr: 0.0050\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 17.1654 - val_loss: 66.5759 - lr: 0.0050\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.8990 - val_loss: 68.2334 - lr: 0.0050\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 17.9443 - val_loss: 67.2013 - lr: 0.0025\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 18.2801 - val_loss: 64.8780 - lr: 0.0025\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 17.5951 - val_loss: 63.8424 - lr: 0.0025\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.0402 - val_loss: 65.1867 - lr: 0.0025\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 16.2680 - val_loss: 67.5412 - lr: 0.0025\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 20.1703 - val_loss: 72.7588 - lr: 0.0025\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 22.9327 - val_loss: 71.0778 - lr: 0.0025\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 29.4971 - val_loss: 58.6468 - lr: 0.0025\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 16.3473 - val_loss: 49.2316 - lr: 0.0025\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.1793 - val_loss: 46.7620 - lr: 0.0025\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.0867 - val_loss: 44.3625 - lr: 0.0025\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 19.7250 - val_loss: 43.2015 - lr: 0.0025\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 17.9138 - val_loss: 42.9190 - lr: 0.0025\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 22.0175 - val_loss: 43.4850 - lr: 0.0025\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 20.5595 - val_loss: 44.4708 - lr: 0.0025\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 18.8259 - val_loss: 45.9594 - lr: 0.0025\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 21.4605 - val_loss: 46.6664 - lr: 0.0025\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 17.3289 - val_loss: 47.0178 - lr: 0.0025\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.8644 - val_loss: 47.2218 - lr: 0.0025\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.2955 - val_loss: 46.7097 - lr: 0.0025\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 17.4647 - val_loss: 46.3249 - lr: 0.0025\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 20.5262 - val_loss: 46.2176 - lr: 0.0025\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 16.3426 - val_loss: 46.8475 - lr: 0.0025\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 15.9321 - val_loss: 50.1339 - lr: 0.0025\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 20.0403 - val_loss: 53.7635 - lr: 0.0025\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.8255 - val_loss: 55.6092 - lr: 0.0025\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.9495 - val_loss: 57.9371 - lr: 0.0025\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.6387 - val_loss: 60.0617 - lr: 0.0025\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 20.7779 - val_loss: 61.2328 - lr: 0.0025\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 17.3442 - val_loss: 61.8324 - lr: 0.0025\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.9645 - val_loss: 62.3562 - lr: 0.0025\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 15.3745 - val_loss: 63.0068 - lr: 0.0025\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 16.6811 - val_loss: 62.7612 - lr: 0.0025\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 17.4128 - val_loss: 62.9014 - lr: 0.0025\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 19.4216 - val_loss: 62.5244 - lr: 0.0025\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.9741 - val_loss: 61.2877 - lr: 0.0025\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.6972 - val_loss: 59.9144 - lr: 0.0025\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.5504 - val_loss: 59.4059 - lr: 0.0025\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 17.7108 - val_loss: 59.9849 - lr: 0.0025\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 16.1355 - val_loss: 60.7605 - lr: 0.0025\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.3224 - val_loss: 62.2370 - lr: 0.0025\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.0770 - val_loss: 64.6084 - lr: 0.0025\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 17.4155 - val_loss: 66.5441 - lr: 0.0025\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 15.4575 - val_loss: 68.4194 - lr: 0.0025\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 20.0848 - val_loss: 70.9856 - lr: 0.0025\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 15.7190 - val_loss: 73.4532 - lr: 0.0025\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.5816 - val_loss: 74.9859 - lr: 0.0025\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.5637 - val_loss: 74.5532 - lr: 0.0025\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 16.2953 - val_loss: 75.8170 - lr: 0.0025\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.3473 - val_loss: 77.6215 - lr: 0.0025\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 13.9605 - val_loss: 77.5377 - lr: 0.0012\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 14.7518 - val_loss: 77.3925 - lr: 0.0012\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 14.2815 - val_loss: 77.3832 - lr: 0.0012\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 17.8659 - val_loss: 78.4647 - lr: 0.0012\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 15.3174 - val_loss: 79.6287 - lr: 0.0012\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 18.3039 - val_loss: 81.0016 - lr: 0.0012\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.9681 - val_loss: 83.2011 - lr: 0.0012\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 13.4989 - val_loss: 85.0127 - lr: 0.0012\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 16.2545 - val_loss: 85.4080 - lr: 0.0012\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 12.8618 - val_loss: 85.5896 - lr: 0.0012\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 16.0130 - val_loss: 85.2913 - lr: 0.0012\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.3102 - val_loss: 83.9358 - lr: 0.0012\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 14.6049 - val_loss: 83.0960 - lr: 0.0012\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 15.9858 - val_loss: 82.3251 - lr: 0.0012\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 19.6747 - val_loss: 81.0025 - lr: 0.0012\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.5421 - val_loss: 79.9405 - lr: 0.0012\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 16.6447 - val_loss: 79.1202 - lr: 0.0012\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 13.2911 - val_loss: 79.0610 - lr: 0.0012\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 14.2629 - val_loss: 78.9177 - lr: 0.0012\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.1277 - val_loss: 78.7855 - lr: 0.0012\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 16.4100 - val_loss: 78.6287 - lr: 0.0012\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.7888 - val_loss: 78.3861 - lr: 0.0012\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 13.1061 - val_loss: 78.2013 - lr: 0.0012\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 13.2782 - val_loss: 78.3832 - lr: 0.0012\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 13.6426 - val_loss: 78.6403 - lr: 0.0012\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.0352 - val_loss: 78.7356 - lr: 0.0012\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.1203 - val_loss: 78.6133 - lr: 0.0012\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 14.4056 - val_loss: 77.7439 - lr: 0.0012\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 11.7092 - val_loss: 76.2642 - lr: 0.0012\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 12.7985 - val_loss: 74.9148 - lr: 0.0012\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.0940 - val_loss: 74.0780 - lr: 0.0012\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 15.6105 - val_loss: 73.2650 - lr: 0.0012\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.4935 - val_loss: 72.0835 - lr: 0.0012\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 15.0305 - val_loss: 70.9690 - lr: 0.0012\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 13.4653 - val_loss: 69.7905 - lr: 0.0012\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 13.6652 - val_loss: 68.6874 - lr: 0.0012\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 14.1838 - val_loss: 67.5963 - lr: 0.0012\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 15.2163 - val_loss: 67.4586 - lr: 0.0012\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 15.0394 - val_loss: 67.4619 - lr: 0.0012\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.8530 - val_loss: 67.3080 - lr: 0.0012\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 16.1616 - val_loss: 67.4274 - lr: 0.0012\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.9991 - val_loss: 67.5632 - lr: 0.0012\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.9128 - val_loss: 67.5641 - lr: 0.0012\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 11.2686 - val_loss: 67.5344 - lr: 0.0012\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 16.2801 - val_loss: 67.8898 - lr: 0.0012\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.4873 - val_loss: 68.5625 - lr: 0.0012\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.2717 - val_loss: 68.5350 - lr: 0.0012\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 15.0343 - val_loss: 68.1270 - lr: 0.0012\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 15.9766 - val_loss: 68.3189 - lr: 0.0012\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 11.0754 - val_loss: 69.0552 - lr: 0.0012\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 13.3426 - val_loss: 69.2020 - lr: 6.2500e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 14.7540 - val_loss: 69.3732 - lr: 6.2500e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 16.9544 - val_loss: 69.8476 - lr: 6.2500e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.0969 - val_loss: 70.1366 - lr: 6.2500e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 15.0060 - val_loss: 69.9981 - lr: 6.2500e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 15.0922 - val_loss: 69.8080 - lr: 6.2500e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.0410 - val_loss: 69.4252 - lr: 6.2500e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.3373 - val_loss: 69.4887 - lr: 6.2500e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 12.0918 - val_loss: 69.8077 - lr: 6.2500e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 11.8872 - val_loss: 70.3183 - lr: 6.2500e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.4460 - val_loss: 70.8383 - lr: 6.2500e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12.8897 - val_loss: 71.5080 - lr: 6.2500e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 10.5707 - val_loss: 72.3192 - lr: 6.2500e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 17.1815 - val_loss: 72.5450 - lr: 6.2500e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.5479 - val_loss: 72.1159 - lr: 6.2500e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 17.8044 - val_loss: 71.9481 - lr: 6.2500e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 15.1241 - val_loss: 71.6187 - lr: 6.2500e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 15.2786 - val_loss: 71.3503 - lr: 6.2500e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.4822 - val_loss: 71.3808 - lr: 6.2500e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 12.2251 - val_loss: 71.1895 - lr: 6.2500e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 16.0130 - val_loss: 71.0896 - lr: 6.2500e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 14.7257 - val_loss: 70.9662 - lr: 6.2500e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 11.6777 - val_loss: 70.5850 - lr: 6.2500e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 14.6911 - val_loss: 70.1372 - lr: 6.2500e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.6461 - val_loss: 69.9465 - lr: 6.2500e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.5037 - val_loss: 69.6483 - lr: 6.2500e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.0210 - val_loss: 69.2741 - lr: 6.2500e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.8072 - val_loss: 68.4352 - lr: 6.2500e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 12.9587 - val_loss: 67.8329 - lr: 6.2500e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 14.0757 - val_loss: 67.7231 - lr: 6.2500e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.7245 - val_loss: 67.8845 - lr: 6.2500e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11.3480 - val_loss: 67.9836 - lr: 6.2500e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11.5564 - val_loss: 67.9069 - lr: 6.2500e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 12.7473 - val_loss: 67.6446 - lr: 6.2500e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 14.3646 - val_loss: 67.5256 - lr: 6.2500e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 17.5711 - val_loss: 67.1469 - lr: 6.2500e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 14.5793 - val_loss: 67.2945 - lr: 6.2500e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.1832 - val_loss: 67.5954 - lr: 6.2500e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 11.9196 - val_loss: 67.8804 - lr: 6.2500e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.6894 - val_loss: 67.7908 - lr: 6.2500e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 16.0686 - val_loss: 67.3116 - lr: 6.2500e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 10.5708 - val_loss: 67.2328 - lr: 6.2500e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 13.1576 - val_loss: 67.4641 - lr: 6.2500e-04\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 11.5811 - val_loss: 67.8925 - lr: 6.2500e-04\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.9168 - val_loss: 68.4581 - lr: 6.2500e-04\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 13.8995 - val_loss: 68.6002 - lr: 6.2500e-04\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 12.8389 - val_loss: 68.5374 - lr: 6.2500e-04\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 13.4612 - val_loss: 68.4197 - lr: 6.2500e-04\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.2609 - val_loss: 68.5015 - lr: 6.2500e-04\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.9927 - val_loss: 68.2919 - lr: 6.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 4/6 [02:46<01:17, 38.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 5s 1s/step - loss: 546.2738 - val_loss: 577.9205 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 538.2002 - val_loss: 586.6618 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 541.2114 - val_loss: 575.2105 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 535.9244 - val_loss: 565.2703 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 528.5172 - val_loss: 568.0727 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 524.1827 - val_loss: 566.9638 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 520.0506 - val_loss: 561.9680 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 516.9675 - val_loss: 553.4391 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 512.3780 - val_loss: 550.3252 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 508.9459 - val_loss: 548.4282 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 501.7331 - val_loss: 543.8366 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 501.3612 - val_loss: 536.5516 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 492.9468 - val_loss: 524.2206 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 484.9619 - val_loss: 516.2822 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 481.0967 - val_loss: 510.7058 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 471.4123 - val_loss: 506.7217 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 462.2623 - val_loss: 507.6952 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 452.5728 - val_loss: 509.5294 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 444.3649 - val_loss: 510.0631 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 432.7795 - val_loss: 501.6831 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 428.1286 - val_loss: 477.2987 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 413.9339 - val_loss: 461.3660 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 397.7611 - val_loss: 464.2397 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 390.3162 - val_loss: 469.5564 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 377.9005 - val_loss: 460.4440 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 367.5182 - val_loss: 448.3661 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 351.3617 - val_loss: 433.6298 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 339.1445 - val_loss: 421.2110 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 325.9423 - val_loss: 407.5713 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 313.1392 - val_loss: 394.5678 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 301.3421 - val_loss: 385.3919 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 282.1885 - val_loss: 368.9522 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 269.7037 - val_loss: 345.1474 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 258.4968 - val_loss: 324.4234 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 246.7880 - val_loss: 314.7499 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 230.4411 - val_loss: 306.9211 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 214.6080 - val_loss: 297.0943 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 205.7845 - val_loss: 289.2523 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 193.3056 - val_loss: 281.7023 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 182.9727 - val_loss: 264.6569 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 168.7065 - val_loss: 237.7040 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 160.6582 - val_loss: 204.7556 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 146.0179 - val_loss: 185.7297 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 137.8270 - val_loss: 176.4188 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 123.6318 - val_loss: 167.7506 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 114.3962 - val_loss: 165.6677 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 107.7898 - val_loss: 160.2228 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 98.6852 - val_loss: 157.2964 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 87.9854 - val_loss: 141.7682 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 85.9207 - val_loss: 129.2955 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 83.0784 - val_loss: 121.1874 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 69.1563 - val_loss: 114.3785 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 60.8407 - val_loss: 108.0398 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 56.4609 - val_loss: 93.7172 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 54.1240 - val_loss: 82.3341 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 45.9081 - val_loss: 80.4442 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 43.5760 - val_loss: 82.4174 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 44.7608 - val_loss: 73.9703 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 36.7765 - val_loss: 63.1381 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 34.0212 - val_loss: 53.5348 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 31.3418 - val_loss: 65.3832 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 32.6214 - val_loss: 84.5856 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 30.5589 - val_loss: 87.7633 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 30.5367 - val_loss: 84.4950 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 28.1099 - val_loss: 87.7440 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 24.8320 - val_loss: 92.8663 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 24.7994 - val_loss: 92.6043 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 26.5822 - val_loss: 87.2389 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 24.1190 - val_loss: 79.0902 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 22.4874 - val_loss: 73.1543 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 22.9632 - val_loss: 74.3105 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 21.6152 - val_loss: 76.5523 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 20.1534 - val_loss: 80.3883 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 22.3585 - val_loss: 83.1732 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 21.7825 - val_loss: 84.7744 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 23.6980 - val_loss: 82.2413 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 22.3484 - val_loss: 82.5685 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 18.8007 - val_loss: 84.2289 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 18.3708 - val_loss: 86.5263 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.0404 - val_loss: 91.7155 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 22.0080 - val_loss: 89.2025 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 19.9605 - val_loss: 88.0169 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 23.3473 - val_loss: 82.1845 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 18.5285 - val_loss: 75.0599 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.5767 - val_loss: 79.2188 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 22.6962 - val_loss: 75.4735 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 22.3609 - val_loss: 71.3442 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 18.5343 - val_loss: 68.7816 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 21.9665 - val_loss: 71.2096 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.9143 - val_loss: 73.4660 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 20.0345 - val_loss: 74.2927 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 21.7231 - val_loss: 76.1060 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.9200 - val_loss: 86.8121 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.3844 - val_loss: 86.0549 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 19.0890 - val_loss: 72.9271 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 15.7221 - val_loss: 78.5363 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.3307 - val_loss: 82.3415 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.2137 - val_loss: 84.5839 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.7966 - val_loss: 86.9576 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 19.7017 - val_loss: 87.2523 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 18.2373 - val_loss: 89.7184 - lr: 0.0050\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 20.0366 - val_loss: 92.9478 - lr: 0.0050\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 17.4624 - val_loss: 105.0188 - lr: 0.0050\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 17.6123 - val_loss: 116.3255 - lr: 0.0050\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.1294 - val_loss: 122.4355 - lr: 0.0050\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 20.0820 - val_loss: 120.6338 - lr: 0.0050\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 20.2793 - val_loss: 120.5821 - lr: 0.0050\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 13.8863 - val_loss: 119.6038 - lr: 0.0050\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.8367 - val_loss: 98.1410 - lr: 0.0050\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 14.9257 - val_loss: 87.9076 - lr: 0.0050\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 19.7105 - val_loss: 85.6013 - lr: 0.0025\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 19.8203 - val_loss: 85.8051 - lr: 0.0025\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.6129 - val_loss: 87.7477 - lr: 0.0025\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 15.9201 - val_loss: 89.4597 - lr: 0.0025\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.6164 - val_loss: 89.5609 - lr: 0.0025\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11.9552 - val_loss: 88.1397 - lr: 0.0025\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 19.4343 - val_loss: 87.9783 - lr: 0.0025\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 17.2205 - val_loss: 89.1445 - lr: 0.0025\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 16.4673 - val_loss: 91.5482 - lr: 0.0025\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 18.3412 - val_loss: 91.9911 - lr: 0.0025\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 16.9902 - val_loss: 92.3579 - lr: 0.0025\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 13.9569 - val_loss: 95.0765 - lr: 0.0025\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.7974 - val_loss: 96.7028 - lr: 0.0025\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.6631 - val_loss: 96.2674 - lr: 0.0025\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 12.9060 - val_loss: 99.2886 - lr: 0.0025\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.6066 - val_loss: 104.4100 - lr: 0.0025\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.4124 - val_loss: 106.7200 - lr: 0.0025\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.8450 - val_loss: 104.9450 - lr: 0.0025\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.8348 - val_loss: 100.8274 - lr: 0.0025\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 12.0403 - val_loss: 98.0190 - lr: 0.0025\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.6114 - val_loss: 95.2033 - lr: 0.0025\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 14.4248 - val_loss: 94.8040 - lr: 0.0025\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 16.0165 - val_loss: 98.8154 - lr: 0.0025\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 12.4848 - val_loss: 96.6498 - lr: 0.0025\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.9184 - val_loss: 90.2253 - lr: 0.0025\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.0654 - val_loss: 87.8550 - lr: 0.0025\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 19.4265 - val_loss: 89.6000 - lr: 0.0025\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.2224 - val_loss: 92.1145 - lr: 0.0025\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.2899 - val_loss: 94.3162 - lr: 0.0025\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.4484 - val_loss: 97.4222 - lr: 0.0025\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.0289 - val_loss: 102.2733 - lr: 0.0025\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 15.7967 - val_loss: 103.8075 - lr: 0.0025\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 12.6285 - val_loss: 101.4999 - lr: 0.0025\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.3740 - val_loss: 99.1205 - lr: 0.0025\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.8885 - val_loss: 97.4321 - lr: 0.0025\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.1259 - val_loss: 95.7935 - lr: 0.0025\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.6152 - val_loss: 94.6528 - lr: 0.0025\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.7917 - val_loss: 95.1875 - lr: 0.0025\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 11.6835 - val_loss: 96.3394 - lr: 0.0025\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 14.1686 - val_loss: 97.5722 - lr: 0.0025\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 16.6789 - val_loss: 97.7878 - lr: 0.0025\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 14.3139 - val_loss: 98.0379 - lr: 0.0025\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.7679 - val_loss: 98.3949 - lr: 0.0025\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 14.1206 - val_loss: 100.8418 - lr: 0.0025\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 16.8378 - val_loss: 104.4303 - lr: 0.0025\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.7894 - val_loss: 109.2599 - lr: 0.0025\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.1961 - val_loss: 113.4339 - lr: 0.0025\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 12.6037 - val_loss: 112.5294 - lr: 0.0025\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 14.3204 - val_loss: 111.4074 - lr: 0.0025\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 11.2018 - val_loss: 108.9277 - lr: 0.0025\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.1762 - val_loss: 105.9690 - lr: 0.0012\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 12.3991 - val_loss: 101.6675 - lr: 0.0012\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.4359 - val_loss: 96.4375 - lr: 0.0012\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 17.9327 - val_loss: 92.3485 - lr: 0.0012\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 15.4432 - val_loss: 92.2884 - lr: 0.0012\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 16.8750 - val_loss: 92.9730 - lr: 0.0012\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 14.3755 - val_loss: 93.5675 - lr: 0.0012\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.0116 - val_loss: 93.6999 - lr: 0.0012\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 13.1832 - val_loss: 94.6734 - lr: 0.0012\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.8939 - val_loss: 95.6671 - lr: 0.0012\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10.5321 - val_loss: 97.7693 - lr: 0.0012\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 13.1310 - val_loss: 98.7415 - lr: 0.0012\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.4202 - val_loss: 98.6071 - lr: 0.0012\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 17.3700 - val_loss: 97.3254 - lr: 0.0012\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10.5401 - val_loss: 94.8514 - lr: 0.0012\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 13.5791 - val_loss: 92.7868 - lr: 0.0012\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.0653 - val_loss: 91.6183 - lr: 0.0012\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.1960 - val_loss: 91.5139 - lr: 0.0012\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 12.9717 - val_loss: 91.2905 - lr: 0.0012\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.8837 - val_loss: 90.1224 - lr: 0.0012\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.6372 - val_loss: 88.7733 - lr: 0.0012\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 13.4993 - val_loss: 87.5478 - lr: 0.0012\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 16.4610 - val_loss: 85.9708 - lr: 0.0012\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.8286 - val_loss: 84.7068 - lr: 0.0012\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 9.4861 - val_loss: 83.9328 - lr: 0.0012\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 13.1246 - val_loss: 83.8178 - lr: 0.0012\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 14.1034 - val_loss: 83.5160 - lr: 0.0012\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 8.6837 - val_loss: 83.6283 - lr: 0.0012\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11.8492 - val_loss: 83.9431 - lr: 0.0012\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.7065 - val_loss: 84.2105 - lr: 0.0012\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 10.5786 - val_loss: 84.3815 - lr: 0.0012\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.9489 - val_loss: 84.8928 - lr: 0.0012\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 12.8335 - val_loss: 85.8483 - lr: 0.0012\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 12.1987 - val_loss: 87.1713 - lr: 0.0012\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 10.2889 - val_loss: 88.1175 - lr: 0.0012\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11.4637 - val_loss: 89.2575 - lr: 0.0012\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 13.2659 - val_loss: 89.9252 - lr: 0.0012\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 14.3267 - val_loss: 90.6104 - lr: 0.0012\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 10.7061 - val_loss: 90.6026 - lr: 0.0012\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12.0058 - val_loss: 90.5936 - lr: 0.0012\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.0390 - val_loss: 90.4137 - lr: 0.0012\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 9.7090 - val_loss: 89.9357 - lr: 0.0012\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 11.7008 - val_loss: 89.2974 - lr: 0.0012\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11.5249 - val_loss: 88.5536 - lr: 0.0012\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 9.8825 - val_loss: 88.1914 - lr: 0.0012\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 11.0652 - val_loss: 87.7506 - lr: 0.0012\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 12.0616 - val_loss: 87.7986 - lr: 0.0012\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 11.7856 - val_loss: 88.2690 - lr: 0.0012\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 11.1714 - val_loss: 89.3883 - lr: 0.0012\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 10.3161 - val_loss: 90.2079 - lr: 0.0012\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 12.6035 - val_loss: 90.8010 - lr: 6.2500e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 11.9327 - val_loss: 91.4302 - lr: 6.2500e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.2817 - val_loss: 91.9263 - lr: 6.2500e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11.7693 - val_loss: 91.9144 - lr: 6.2500e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 14.6452 - val_loss: 91.7132 - lr: 6.2500e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12.7581 - val_loss: 91.5816 - lr: 6.2500e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10.2589 - val_loss: 91.7231 - lr: 6.2500e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 13.6181 - val_loss: 91.0637 - lr: 6.2500e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 9.6539 - val_loss: 90.2609 - lr: 6.2500e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12.7111 - val_loss: 89.6000 - lr: 6.2500e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 9.2893 - val_loss: 89.1170 - lr: 6.2500e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10.4178 - val_loss: 88.9996 - lr: 6.2500e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 10.6090 - val_loss: 89.1420 - lr: 6.2500e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 10.2871 - val_loss: 89.4145 - lr: 6.2500e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11.1846 - val_loss: 89.6049 - lr: 6.2500e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.7744 - val_loss: 89.7529 - lr: 6.2500e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 14.6205 - val_loss: 89.5510 - lr: 6.2500e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.0858 - val_loss: 89.4733 - lr: 6.2500e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 11.4379 - val_loss: 88.8343 - lr: 6.2500e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.1342 - val_loss: 88.8502 - lr: 6.2500e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 10.7831 - val_loss: 89.1069 - lr: 6.2500e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 11.5790 - val_loss: 89.3872 - lr: 6.2500e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 10.6012 - val_loss: 89.4125 - lr: 6.2500e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 13.2999 - val_loss: 89.6447 - lr: 6.2500e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 13.0734 - val_loss: 90.0540 - lr: 6.2500e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.8714 - val_loss: 90.5400 - lr: 6.2500e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 9.0946 - val_loss: 91.2971 - lr: 6.2500e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 10.9733 - val_loss: 91.5959 - lr: 6.2500e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 10.2262 - val_loss: 91.4957 - lr: 6.2500e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10.5909 - val_loss: 91.3000 - lr: 6.2500e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 13.1582 - val_loss: 90.5746 - lr: 6.2500e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.9292 - val_loss: 89.6947 - lr: 6.2500e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 13.5807 - val_loss: 89.4544 - lr: 6.2500e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 10.7533 - val_loss: 89.4990 - lr: 6.2500e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 11.7701 - val_loss: 89.3284 - lr: 6.2500e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 9.2468 - val_loss: 89.3538 - lr: 6.2500e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 10.1554 - val_loss: 89.5291 - lr: 6.2500e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 9.9746 - val_loss: 89.6606 - lr: 6.2500e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11.8972 - val_loss: 89.4080 - lr: 6.2500e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12.5686 - val_loss: 88.6686 - lr: 6.2500e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13.2187 - val_loss: 87.6245 - lr: 6.2500e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 9.0573 - val_loss: 86.5615 - lr: 6.2500e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.8178 - val_loss: 85.8135 - lr: 6.2500e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 11.3070 - val_loss: 85.7839 - lr: 6.2500e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 12.1066 - val_loss: 85.7681 - lr: 6.2500e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 10.7093 - val_loss: 85.3817 - lr: 6.2500e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 12.3496 - val_loss: 85.8940 - lr: 6.2500e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10.4657 - val_loss: 86.3663 - lr: 6.2500e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11.8751 - val_loss: 86.7616 - lr: 6.2500e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 10.8425 - val_loss: 87.1347 - lr: 6.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 5/6 [03:35<00:42, 42.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3/3 [==============================] - 6s 680ms/step - loss: 554.5953 - val_loss: 742.0412 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 546.2175 - val_loss: 728.9532 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 538.0629 - val_loss: 714.6638 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 537.7101 - val_loss: 711.1800 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 531.8442 - val_loss: 715.4899 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 524.4498 - val_loss: 712.2538 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 516.0999 - val_loss: 706.5089 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 509.9872 - val_loss: 691.7772 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 499.9291 - val_loss: 674.2071 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 489.4940 - val_loss: 655.6467 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 484.4150 - val_loss: 638.7559 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 467.8553 - val_loss: 624.0657 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 453.1821 - val_loss: 613.3411 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 445.9656 - val_loss: 597.3224 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 427.0783 - val_loss: 576.5527 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 410.9117 - val_loss: 558.0755 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 392.4302 - val_loss: 534.5637 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 376.4257 - val_loss: 510.7809 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 354.8748 - val_loss: 482.7578 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 339.4057 - val_loss: 449.7334 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 316.2585 - val_loss: 421.9905 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 299.1929 - val_loss: 400.3282 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 283.5294 - val_loss: 384.2948 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 261.8827 - val_loss: 358.2941 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 243.4208 - val_loss: 330.9668 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 222.0877 - val_loss: 323.0931 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 204.0007 - val_loss: 304.8268 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 184.4753 - val_loss: 277.9034 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 169.2573 - val_loss: 264.5141 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 156.5907 - val_loss: 258.8880 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "3/3 [==============================] - 0s 235ms/step - loss: 140.2502 - val_loss: 246.9157 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 124.6338 - val_loss: 231.0920 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 114.6376 - val_loss: 209.5461 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 102.4290 - val_loss: 197.1744 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 89.0847 - val_loss: 184.9717 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 76.0375 - val_loss: 150.4939 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 68.3470 - val_loss: 126.8477 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 64.6044 - val_loss: 128.8199 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 56.2167 - val_loss: 115.3329 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 50.7047 - val_loss: 101.2162 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 50.9288 - val_loss: 95.0974 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 45.2317 - val_loss: 90.0291 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 38.7556 - val_loss: 87.0183 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 45.2349 - val_loss: 81.6519 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 39.4565 - val_loss: 76.4614 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 34.8599 - val_loss: 71.8172 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 39.9212 - val_loss: 80.5746 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 37.7685 - val_loss: 86.7976 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 28.1019 - val_loss: 88.8415 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.8506 - val_loss: 83.6947 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 29.0511 - val_loss: 75.2909 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 33.3186 - val_loss: 70.9992 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 28.8817 - val_loss: 69.3581 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 34.6782 - val_loss: 71.0424 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 28.2230 - val_loss: 73.3269 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 33.3476 - val_loss: 71.6972 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 26.2639 - val_loss: 69.5238 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 30.3345 - val_loss: 63.6863 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 27.6551 - val_loss: 61.4583 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 27.2539 - val_loss: 64.7956 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 31.4431 - val_loss: 66.3569 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 32.0619 - val_loss: 63.4651 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 26.8421 - val_loss: 67.9552 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 30.5059 - val_loss: 75.9249 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 31.4923 - val_loss: 77.9555 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 29.6944 - val_loss: 72.3268 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 31.2120 - val_loss: 67.0174 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 29.6441 - val_loss: 70.9287 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 34.7242 - val_loss: 64.8989 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 28.5638 - val_loss: 63.7960 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 27.9872 - val_loss: 68.2584 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 27.2455 - val_loss: 70.3539 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 29.3313 - val_loss: 68.7674 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 25.3823 - val_loss: 65.8893 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 28.5936 - val_loss: 70.6836 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 28.1340 - val_loss: 76.0225 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 28.7866 - val_loss: 72.9077 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 29.5734 - val_loss: 66.3068 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 27.5174 - val_loss: 59.8200 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 28.8308 - val_loss: 55.7710 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 25.2825 - val_loss: 55.8704 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 26.2707 - val_loss: 59.4223 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 31.1731 - val_loss: 64.4418 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 31.7690 - val_loss: 61.1842 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 27.1505 - val_loss: 62.1253 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 27.4168 - val_loss: 72.0277 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 28.5986 - val_loss: 75.6186 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 24.9010 - val_loss: 75.7083 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 28.3317 - val_loss: 72.8703 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 26.2618 - val_loss: 64.9821 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 25.6175 - val_loss: 57.5839 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 26.9386 - val_loss: 55.3869 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 28.4791 - val_loss: 64.8883 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 28.2379 - val_loss: 71.2121 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 27.1477 - val_loss: 73.8838 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 27.3834 - val_loss: 70.7812 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.0366 - val_loss: 74.6321 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 26.3694 - val_loss: 66.1054 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 25.6528 - val_loss: 60.7130 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 25.2512 - val_loss: 63.9881 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.1094 - val_loss: 70.7477 - lr: 0.0050\n",
            "Epoch 102/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.3085 - val_loss: 74.2119 - lr: 0.0050\n",
            "Epoch 103/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 28.3512 - val_loss: 64.9024 - lr: 0.0050\n",
            "Epoch 104/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.1737 - val_loss: 55.6467 - lr: 0.0050\n",
            "Epoch 105/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 26.0831 - val_loss: 55.8738 - lr: 0.0050\n",
            "Epoch 106/1000\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 23.1215 - val_loss: 52.1262 - lr: 0.0050\n",
            "Epoch 107/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 26.3580 - val_loss: 50.0857 - lr: 0.0050\n",
            "Epoch 108/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 22.4965 - val_loss: 54.7442 - lr: 0.0050\n",
            "Epoch 109/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 23.8132 - val_loss: 69.6496 - lr: 0.0050\n",
            "Epoch 110/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 26.5104 - val_loss: 81.2011 - lr: 0.0050\n",
            "Epoch 111/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.1753 - val_loss: 90.3177 - lr: 0.0050\n",
            "Epoch 112/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 25.2328 - val_loss: 104.0923 - lr: 0.0050\n",
            "Epoch 113/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 22.6186 - val_loss: 108.2191 - lr: 0.0050\n",
            "Epoch 114/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 29.9307 - val_loss: 102.0004 - lr: 0.0050\n",
            "Epoch 115/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 28.9237 - val_loss: 88.8203 - lr: 0.0050\n",
            "Epoch 116/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 28.8168 - val_loss: 102.2254 - lr: 0.0050\n",
            "Epoch 117/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 28.1167 - val_loss: 97.9180 - lr: 0.0050\n",
            "Epoch 118/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 22.9496 - val_loss: 78.2072 - lr: 0.0050\n",
            "Epoch 119/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 26.5096 - val_loss: 85.2961 - lr: 0.0050\n",
            "Epoch 120/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.5473 - val_loss: 99.5810 - lr: 0.0050\n",
            "Epoch 121/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 22.5384 - val_loss: 106.2096 - lr: 0.0050\n",
            "Epoch 122/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.4857 - val_loss: 106.3718 - lr: 0.0050\n",
            "Epoch 123/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 22.8516 - val_loss: 95.4454 - lr: 0.0050\n",
            "Epoch 124/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 20.5760 - val_loss: 93.4889 - lr: 0.0050\n",
            "Epoch 125/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 24.6879 - val_loss: 93.3129 - lr: 0.0050\n",
            "Epoch 126/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 25.0488 - val_loss: 91.5239 - lr: 0.0050\n",
            "Epoch 127/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 27.3512 - val_loss: 97.8615 - lr: 0.0050\n",
            "Epoch 128/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 25.9660 - val_loss: 100.6656 - lr: 0.0050\n",
            "Epoch 129/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 27.6701 - val_loss: 86.7505 - lr: 0.0050\n",
            "Epoch 130/1000\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 25.6042 - val_loss: 73.9835 - lr: 0.0050\n",
            "Epoch 131/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 26.2299 - val_loss: 67.6013 - lr: 0.0050\n",
            "Epoch 132/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.3769 - val_loss: 65.9946 - lr: 0.0050\n",
            "Epoch 133/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 23.3665 - val_loss: 73.2575 - lr: 0.0050\n",
            "Epoch 134/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 26.6213 - val_loss: 84.3735 - lr: 0.0050\n",
            "Epoch 135/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 22.3799 - val_loss: 97.4678 - lr: 0.0050\n",
            "Epoch 136/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 22.2809 - val_loss: 109.5574 - lr: 0.0050\n",
            "Epoch 137/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 22.1782 - val_loss: 108.7070 - lr: 0.0050\n",
            "Epoch 138/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 26.5734 - val_loss: 124.8480 - lr: 0.0050\n",
            "Epoch 139/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.1291 - val_loss: 128.6826 - lr: 0.0050\n",
            "Epoch 140/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 19.5790 - val_loss: 112.8563 - lr: 0.0050\n",
            "Epoch 141/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 25.1204 - val_loss: 106.8734 - lr: 0.0050\n",
            "Epoch 142/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 26.7742 - val_loss: 113.0723 - lr: 0.0050\n",
            "Epoch 143/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 25.3023 - val_loss: 119.4254 - lr: 0.0050\n",
            "Epoch 144/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 27.1839 - val_loss: 121.3166 - lr: 0.0050\n",
            "Epoch 145/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.8017 - val_loss: 105.1359 - lr: 0.0050\n",
            "Epoch 146/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.7660 - val_loss: 83.6222 - lr: 0.0050\n",
            "Epoch 147/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 27.2815 - val_loss: 78.7709 - lr: 0.0050\n",
            "Epoch 148/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 25.6111 - val_loss: 86.1041 - lr: 0.0050\n",
            "Epoch 149/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 22.9389 - val_loss: 91.5153 - lr: 0.0050\n",
            "Epoch 150/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 26.7924 - val_loss: 85.9013 - lr: 0.0050\n",
            "Epoch 151/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 23.9716 - val_loss: 68.6237 - lr: 0.0050\n",
            "Epoch 152/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.6192 - val_loss: 74.0614 - lr: 0.0050\n",
            "Epoch 153/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 21.6196 - val_loss: 76.1758 - lr: 0.0050\n",
            "Epoch 154/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 30.0566 - val_loss: 82.1874 - lr: 0.0050\n",
            "Epoch 155/1000\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 20.0996 - val_loss: 83.6880 - lr: 0.0050\n",
            "Epoch 156/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 20.8905 - val_loss: 123.7024 - lr: 0.0050\n",
            "Epoch 157/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 21.2146 - val_loss: 102.2066 - lr: 0.0050\n",
            "Epoch 158/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 23.4046 - val_loss: 92.7554 - lr: 0.0025\n",
            "Epoch 159/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.3114 - val_loss: 97.9945 - lr: 0.0025\n",
            "Epoch 160/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 24.3107 - val_loss: 109.2302 - lr: 0.0025\n",
            "Epoch 161/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.1179 - val_loss: 111.5012 - lr: 0.0025\n",
            "Epoch 162/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 21.4865 - val_loss: 103.0304 - lr: 0.0025\n",
            "Epoch 163/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 27.5387 - val_loss: 94.0833 - lr: 0.0025\n",
            "Epoch 164/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 19.4019 - val_loss: 90.9671 - lr: 0.0025\n",
            "Epoch 165/1000\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 19.1770 - val_loss: 92.3873 - lr: 0.0025\n",
            "Epoch 166/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 19.5966 - val_loss: 92.6604 - lr: 0.0025\n",
            "Epoch 167/1000\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 22.3957 - val_loss: 90.4972 - lr: 0.0025\n",
            "Epoch 168/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 19.9081 - val_loss: 88.3188 - lr: 0.0025\n",
            "Epoch 169/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 19.5727 - val_loss: 87.3107 - lr: 0.0025\n",
            "Epoch 170/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 21.4537 - val_loss: 87.1463 - lr: 0.0025\n",
            "Epoch 171/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 16.7829 - val_loss: 87.2845 - lr: 0.0025\n",
            "Epoch 172/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 20.2936 - val_loss: 94.1681 - lr: 0.0025\n",
            "Epoch 173/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 18.5740 - val_loss: 103.2867 - lr: 0.0025\n",
            "Epoch 174/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 18.5351 - val_loss: 104.7774 - lr: 0.0025\n",
            "Epoch 175/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 19.8214 - val_loss: 101.1885 - lr: 0.0025\n",
            "Epoch 176/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.3443 - val_loss: 98.7258 - lr: 0.0025\n",
            "Epoch 177/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 18.9162 - val_loss: 98.9240 - lr: 0.0025\n",
            "Epoch 178/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 17.2166 - val_loss: 97.1720 - lr: 0.0025\n",
            "Epoch 179/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.3260 - val_loss: 95.9265 - lr: 0.0025\n",
            "Epoch 180/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 23.2326 - val_loss: 91.0595 - lr: 0.0025\n",
            "Epoch 181/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 18.5232 - val_loss: 85.5784 - lr: 0.0025\n",
            "Epoch 182/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 20.6396 - val_loss: 83.5616 - lr: 0.0025\n",
            "Epoch 183/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 18.8683 - val_loss: 82.5084 - lr: 0.0025\n",
            "Epoch 184/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.8701 - val_loss: 81.1524 - lr: 0.0025\n",
            "Epoch 185/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 15.4571 - val_loss: 81.4789 - lr: 0.0025\n",
            "Epoch 186/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.7843 - val_loss: 87.6230 - lr: 0.0025\n",
            "Epoch 187/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.9031 - val_loss: 95.8079 - lr: 0.0025\n",
            "Epoch 188/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 19.4316 - val_loss: 100.0929 - lr: 0.0025\n",
            "Epoch 189/1000\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 15.2058 - val_loss: 101.3200 - lr: 0.0025\n",
            "Epoch 190/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.8235 - val_loss: 107.2932 - lr: 0.0025\n",
            "Epoch 191/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15.7043 - val_loss: 116.3854 - lr: 0.0025\n",
            "Epoch 192/1000\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 20.1889 - val_loss: 121.5672 - lr: 0.0025\n",
            "Epoch 193/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.6666 - val_loss: 122.5974 - lr: 0.0025\n",
            "Epoch 194/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.1681 - val_loss: 120.1184 - lr: 0.0025\n",
            "Epoch 195/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 16.5206 - val_loss: 119.1334 - lr: 0.0025\n",
            "Epoch 196/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.2836 - val_loss: 120.7863 - lr: 0.0025\n",
            "Epoch 197/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.6619 - val_loss: 124.3015 - lr: 0.0025\n",
            "Epoch 198/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 17.0215 - val_loss: 124.7705 - lr: 0.0025\n",
            "Epoch 199/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.9853 - val_loss: 122.6794 - lr: 0.0025\n",
            "Epoch 200/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.3877 - val_loss: 118.4204 - lr: 0.0025\n",
            "Epoch 201/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 20.5129 - val_loss: 112.2678 - lr: 0.0025\n",
            "Epoch 202/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 21.6777 - val_loss: 103.6672 - lr: 0.0025\n",
            "Epoch 203/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 16.4232 - val_loss: 98.0373 - lr: 0.0025\n",
            "Epoch 204/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.9044 - val_loss: 89.8230 - lr: 0.0025\n",
            "Epoch 205/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 17.2056 - val_loss: 82.0542 - lr: 0.0025\n",
            "Epoch 206/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.0850 - val_loss: 77.9728 - lr: 0.0025\n",
            "Epoch 207/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 21.6543 - val_loss: 75.1258 - lr: 0.0025\n",
            "Epoch 208/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 19.6615 - val_loss: 74.4241 - lr: 0.0012\n",
            "Epoch 209/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 17.8114 - val_loss: 75.2716 - lr: 0.0012\n",
            "Epoch 210/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 19.9558 - val_loss: 76.5475 - lr: 0.0012\n",
            "Epoch 211/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.9968 - val_loss: 78.5462 - lr: 0.0012\n",
            "Epoch 212/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 23.7898 - val_loss: 80.4786 - lr: 0.0012\n",
            "Epoch 213/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 18.2528 - val_loss: 81.8738 - lr: 0.0012\n",
            "Epoch 214/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 16.2085 - val_loss: 82.3586 - lr: 0.0012\n",
            "Epoch 215/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15.8088 - val_loss: 84.0494 - lr: 0.0012\n",
            "Epoch 216/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 16.6200 - val_loss: 84.8849 - lr: 0.0012\n",
            "Epoch 217/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 18.5924 - val_loss: 85.2270 - lr: 0.0012\n",
            "Epoch 218/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.7505 - val_loss: 86.7505 - lr: 0.0012\n",
            "Epoch 219/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.8620 - val_loss: 89.0854 - lr: 0.0012\n",
            "Epoch 220/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 18.3730 - val_loss: 90.8520 - lr: 0.0012\n",
            "Epoch 221/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 19.2806 - val_loss: 94.5615 - lr: 0.0012\n",
            "Epoch 222/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.8212 - val_loss: 98.0649 - lr: 0.0012\n",
            "Epoch 223/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.0076 - val_loss: 99.9291 - lr: 0.0012\n",
            "Epoch 224/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 19.8375 - val_loss: 100.3380 - lr: 0.0012\n",
            "Epoch 225/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.9551 - val_loss: 101.4528 - lr: 0.0012\n",
            "Epoch 226/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.2869 - val_loss: 101.4517 - lr: 0.0012\n",
            "Epoch 227/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 12.7503 - val_loss: 102.5094 - lr: 0.0012\n",
            "Epoch 228/1000\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 16.1227 - val_loss: 103.5103 - lr: 0.0012\n",
            "Epoch 229/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 17.4118 - val_loss: 103.0848 - lr: 0.0012\n",
            "Epoch 230/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.2264 - val_loss: 104.0101 - lr: 0.0012\n",
            "Epoch 231/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.3859 - val_loss: 103.2221 - lr: 0.0012\n",
            "Epoch 232/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 18.5672 - val_loss: 103.0947 - lr: 0.0012\n",
            "Epoch 233/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 16.5790 - val_loss: 102.7082 - lr: 0.0012\n",
            "Epoch 234/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.5169 - val_loss: 101.6655 - lr: 0.0012\n",
            "Epoch 235/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.8722 - val_loss: 100.4538 - lr: 0.0012\n",
            "Epoch 236/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 14.5446 - val_loss: 99.8877 - lr: 0.0012\n",
            "Epoch 237/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.1881 - val_loss: 100.2254 - lr: 0.0012\n",
            "Epoch 238/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.3962 - val_loss: 100.4842 - lr: 0.0012\n",
            "Epoch 239/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 14.5756 - val_loss: 100.9241 - lr: 0.0012\n",
            "Epoch 240/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 17.7890 - val_loss: 97.9039 - lr: 0.0012\n",
            "Epoch 241/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 15.9013 - val_loss: 93.6722 - lr: 0.0012\n",
            "Epoch 242/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.2166 - val_loss: 91.8040 - lr: 0.0012\n",
            "Epoch 243/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.0837 - val_loss: 89.7315 - lr: 0.0012\n",
            "Epoch 244/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.6603 - val_loss: 87.4369 - lr: 0.0012\n",
            "Epoch 245/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 18.2341 - val_loss: 86.0020 - lr: 0.0012\n",
            "Epoch 246/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.1992 - val_loss: 85.6740 - lr: 0.0012\n",
            "Epoch 247/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.7913 - val_loss: 86.4271 - lr: 0.0012\n",
            "Epoch 248/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.6449 - val_loss: 89.5205 - lr: 0.0012\n",
            "Epoch 249/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 14.0061 - val_loss: 93.8659 - lr: 0.0012\n",
            "Epoch 250/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 14.9210 - val_loss: 97.7723 - lr: 0.0012\n",
            "Epoch 251/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.2066 - val_loss: 100.6176 - lr: 0.0012\n",
            "Epoch 252/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.3155 - val_loss: 99.3828 - lr: 0.0012\n",
            "Epoch 253/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 15.9424 - val_loss: 98.5183 - lr: 0.0012\n",
            "Epoch 254/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.3527 - val_loss: 95.9425 - lr: 0.0012\n",
            "Epoch 255/1000\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 16.6560 - val_loss: 94.6344 - lr: 0.0012\n",
            "Epoch 256/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 13.9200 - val_loss: 94.4104 - lr: 0.0012\n",
            "Epoch 257/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 16.7353 - val_loss: 94.4035 - lr: 0.0012\n",
            "Epoch 258/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 18.8022 - val_loss: 95.3946 - lr: 6.2500e-04\n",
            "Epoch 259/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.8274 - val_loss: 97.1650 - lr: 6.2500e-04\n",
            "Epoch 260/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 17.1688 - val_loss: 98.0301 - lr: 6.2500e-04\n",
            "Epoch 261/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.4808 - val_loss: 100.0124 - lr: 6.2500e-04\n",
            "Epoch 262/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.9186 - val_loss: 100.3146 - lr: 6.2500e-04\n",
            "Epoch 263/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.6506 - val_loss: 100.2208 - lr: 6.2500e-04\n",
            "Epoch 264/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.7269 - val_loss: 100.6470 - lr: 6.2500e-04\n",
            "Epoch 265/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.1525 - val_loss: 101.0730 - lr: 6.2500e-04\n",
            "Epoch 266/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 13.2433 - val_loss: 101.4057 - lr: 6.2500e-04\n",
            "Epoch 267/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.3872 - val_loss: 101.0754 - lr: 6.2500e-04\n",
            "Epoch 268/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.4137 - val_loss: 99.8210 - lr: 6.2500e-04\n",
            "Epoch 269/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 12.6640 - val_loss: 98.5624 - lr: 6.2500e-04\n",
            "Epoch 270/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 16.1737 - val_loss: 97.4193 - lr: 6.2500e-04\n",
            "Epoch 271/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.3462 - val_loss: 95.8843 - lr: 6.2500e-04\n",
            "Epoch 272/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.9768 - val_loss: 93.9763 - lr: 6.2500e-04\n",
            "Epoch 273/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.1491 - val_loss: 93.6832 - lr: 6.2500e-04\n",
            "Epoch 274/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 17.1750 - val_loss: 92.5350 - lr: 6.2500e-04\n",
            "Epoch 275/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 13.0853 - val_loss: 91.5511 - lr: 6.2500e-04\n",
            "Epoch 276/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 15.9464 - val_loss: 91.0351 - lr: 6.2500e-04\n",
            "Epoch 277/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 14.5520 - val_loss: 90.7463 - lr: 6.2500e-04\n",
            "Epoch 278/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.3524 - val_loss: 89.8791 - lr: 6.2500e-04\n",
            "Epoch 279/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.3297 - val_loss: 89.8095 - lr: 6.2500e-04\n",
            "Epoch 280/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 13.6999 - val_loss: 88.4376 - lr: 6.2500e-04\n",
            "Epoch 281/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 13.9179 - val_loss: 87.8956 - lr: 6.2500e-04\n",
            "Epoch 282/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 14.2139 - val_loss: 87.7143 - lr: 6.2500e-04\n",
            "Epoch 283/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.2149 - val_loss: 87.8084 - lr: 6.2500e-04\n",
            "Epoch 284/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 14.3931 - val_loss: 88.5546 - lr: 6.2500e-04\n",
            "Epoch 285/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.8899 - val_loss: 89.6608 - lr: 6.2500e-04\n",
            "Epoch 286/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.1339 - val_loss: 90.3913 - lr: 6.2500e-04\n",
            "Epoch 287/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 18.0941 - val_loss: 90.9948 - lr: 6.2500e-04\n",
            "Epoch 288/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 13.8152 - val_loss: 91.6923 - lr: 6.2500e-04\n",
            "Epoch 289/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.4678 - val_loss: 94.4655 - lr: 6.2500e-04\n",
            "Epoch 290/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 14.0104 - val_loss: 96.4775 - lr: 6.2500e-04\n",
            "Epoch 291/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 13.5875 - val_loss: 97.3999 - lr: 6.2500e-04\n",
            "Epoch 292/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.6952 - val_loss: 98.2343 - lr: 6.2500e-04\n",
            "Epoch 293/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.8641 - val_loss: 99.0091 - lr: 6.2500e-04\n",
            "Epoch 294/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.6381 - val_loss: 99.5830 - lr: 6.2500e-04\n",
            "Epoch 295/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.6557 - val_loss: 99.1779 - lr: 6.2500e-04\n",
            "Epoch 296/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 20.3526 - val_loss: 98.4742 - lr: 6.2500e-04\n",
            "Epoch 297/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.0981 - val_loss: 98.4180 - lr: 6.2500e-04\n",
            "Epoch 298/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.3980 - val_loss: 97.1945 - lr: 6.2500e-04\n",
            "Epoch 299/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 14.2390 - val_loss: 97.0487 - lr: 6.2500e-04\n",
            "Epoch 300/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 12.8652 - val_loss: 97.5570 - lr: 6.2500e-04\n",
            "Epoch 301/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 13.1317 - val_loss: 98.0728 - lr: 6.2500e-04\n",
            "Epoch 302/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.0741 - val_loss: 99.0042 - lr: 6.2500e-04\n",
            "Epoch 303/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.1704 - val_loss: 100.9086 - lr: 6.2500e-04\n",
            "Epoch 304/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 12.9095 - val_loss: 101.7492 - lr: 6.2500e-04\n",
            "Epoch 305/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.2437 - val_loss: 101.8904 - lr: 6.2500e-04\n",
            "Epoch 306/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.0362 - val_loss: 102.7670 - lr: 6.2500e-04\n",
            "Epoch 307/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 14.7567 - val_loss: 103.3327 - lr: 6.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [04:16<00:00, 42.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 2s, sys: 14.3 s, total: 3min 16s\n",
            "Wall time: 4min 16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_lst_1, rmse_lst_2"
      ],
      "metadata": {
        "id": "OOkG6D8DXMeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7306ba-a20d-4884-a1f2-4a3bdbbfc4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4.320493798938574,\n",
              "  3.851406669430448,\n",
              "  3.2015621187164243,\n",
              "  3.2015621187164243,\n",
              "  5.809475019311125,\n",
              "  5.212165257037297],\n",
              " [23.512408071767837,\n",
              "  18.79716290649558,\n",
              "  21.550328690455437,\n",
              "  24.07972868064201,\n",
              "  26.78619047195775,\n",
              "  33.4165627596057])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_lst_1, mae_lst_2"
      ],
      "metadata": {
        "id": "KkxIbdeFXQEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a46f55-1bf7-4c91-a222-f4b2a27929f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3.8333333333333335,\n",
              "  2.8333333333333335,\n",
              "  2.4166666666666665,\n",
              "  2.5833333333333335,\n",
              "  4.583333333333333,\n",
              "  4.333333333333333],\n",
              " [22.833333333333332,\n",
              "  18.333333333333332,\n",
              "  20.25,\n",
              "  22.0,\n",
              "  25.833333333333332,\n",
              "  31.166666666666668])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medae_lst_1, medae_lst_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OVJV2Y1FYTQ",
        "outputId": "55dd9f6a-999a-40b6-c4dc-374b273acd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3.5, 2.0, 2.0, 2.0, 3.0, 4.0], [23.5, 18.0, 20.0, 21.5, 23.5, 26.0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_lst_1, r2_lst_2"
      ],
      "metadata": {
        "id": "373xfY62XSZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd37e66b-a9dd-404e-f479-4df62927286c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([-2.7178423236514524,\n",
              "  -0.2654028436018956,\n",
              "  -0.08929889298892979,\n",
              "  -0.06034482758620685,\n",
              "  -0.6718266253869969,\n",
              "  -1.7414155571128243],\n",
              " [-16.60070749502543,\n",
              "  -19.483091787439612,\n",
              "  -7.5442698351858954,\n",
              "  -5.066700574002762,\n",
              "  -12.783351120597656,\n",
              "  -6.424165473936932])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_1 = sum(rmse_lst_1) / len(rmse_lst_1)\n",
        "rmse_2 = sum(rmse_lst_2) / len(rmse_lst_2)\n",
        "mae_1 = sum(mae_lst_1) / len(mae_lst_1)\n",
        "mae_2 = sum(mae_lst_2) / len(mae_lst_2)\n",
        "medae_1 = sum(medae_lst_1) / len(medae_lst_1)\n",
        "medae_2 = sum(medae_lst_2) / len(medae_lst_2)\n",
        "r2_1 = sum(r2_lst_1) / len(r2_lst_1)\n",
        "r2_2 = sum(r2_lst_2) / len(r2_lst_2)\n",
        "\n",
        "print(\"Type I crime amount: \\n RMSE: \" + str(rmse_1) + \"\\n MAE: \" + str(mae_1) + \"\\n MEDAE: \" + str(medae_1) + \"\\n R2: \" + str(r2_1) + \n",
        "      \"\\n \\n Type II crime amount: \\n RMSE: \" + str(rmse_2) + \"\\n MAE: \" + str(mae_2) + \"\\n MEDAE: \" + str(medae_1) + \"\\n R2: \" + str(r2_2))"
      ],
      "metadata": {
        "id": "3ffiXhfKvhW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8344f18-95e0-415f-9a3d-e54ba42d6d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type I crime amount: \n",
            " RMSE: 4.266110830358382\n",
            " MAE: 3.4305555555555554\n",
            " MEDAE: 2.75\n",
            " R2: -0.9243551783880509\n",
            " \n",
            " Type II crime amount: \n",
            " RMSE: 24.69039693015405\n",
            " MAE: 23.402777777777775\n",
            " MEDAE: 2.75\n",
            " R2: -11.317047714364714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_real_predict = train(df_need, 108, 24, False, \"Nil\")\n",
        "df_real_predict"
      ],
      "metadata": {
        "id": "bPNxZ1GFtoVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5468c974-89ac-44cc-94d4-257bb88ddaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3/3 [==============================] - 6s 658ms/step - loss: 581.3675 - val_loss: 944.2668 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 575.4476 - val_loss: 935.4475 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 567.3640 - val_loss: 928.8610 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 561.4554 - val_loss: 922.5911 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 556.1551 - val_loss: 916.9710 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 549.6816 - val_loss: 910.9499 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 543.0044 - val_loss: 892.5588 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 535.6238 - val_loss: 879.2856 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 522.2726 - val_loss: 882.3660 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 519.0591 - val_loss: 878.5953 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 500.0244 - val_loss: 888.3502 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 491.9005 - val_loss: 887.8080 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 478.3256 - val_loss: 842.8082 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 457.8233 - val_loss: 799.6387 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 447.1168 - val_loss: 749.2258 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 421.0064 - val_loss: 747.2173 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 406.3738 - val_loss: 722.9152 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 389.0628 - val_loss: 720.9263 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 369.6076 - val_loss: 708.1160 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 346.3279 - val_loss: 646.5145 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 325.6672 - val_loss: 587.5336 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 301.5250 - val_loss: 554.0694 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 284.1512 - val_loss: 529.8989 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 261.1146 - val_loss: 524.4828 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 238.5923 - val_loss: 533.8022 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 218.3719 - val_loss: 504.7123 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 195.3226 - val_loss: 492.1141 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 178.2598 - val_loss: 481.9860 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 160.0934 - val_loss: 433.5812 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 150.9298 - val_loss: 362.6104 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 134.9147 - val_loss: 327.9569 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 121.9642 - val_loss: 315.0650 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 106.3378 - val_loss: 300.6792 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 95.9660 - val_loss: 277.8065 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 91.3570 - val_loss: 264.1360 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 77.4736 - val_loss: 257.4900 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 73.8954 - val_loss: 222.5565 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 60.7801 - val_loss: 188.4163 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 55.7396 - val_loss: 171.2869 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 47.1701 - val_loss: 148.8192 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 43.8263 - val_loss: 136.4282 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 40.9347 - val_loss: 132.0857 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 41.1172 - val_loss: 130.0179 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 37.0304 - val_loss: 125.6890 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 30.5385 - val_loss: 118.9584 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 32.5082 - val_loss: 122.3650 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 37.5934 - val_loss: 143.7566 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 31.8370 - val_loss: 148.1467 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 33.3602 - val_loss: 149.9172 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 33.8270 - val_loss: 158.6795 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 29.6943 - val_loss: 175.4341 - lr: 0.0050\n",
            "Epoch 52/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 30.2196 - val_loss: 150.7667 - lr: 0.0050\n",
            "Epoch 53/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 29.1898 - val_loss: 132.8859 - lr: 0.0050\n",
            "Epoch 54/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 33.1341 - val_loss: 124.4029 - lr: 0.0050\n",
            "Epoch 55/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 31.4739 - val_loss: 130.5092 - lr: 0.0050\n",
            "Epoch 56/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 30.4623 - val_loss: 145.6750 - lr: 0.0050\n",
            "Epoch 57/1000\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 38.8596 - val_loss: 113.3408 - lr: 0.0050\n",
            "Epoch 58/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 31.4756 - val_loss: 109.0298 - lr: 0.0050\n",
            "Epoch 59/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 27.2082 - val_loss: 111.5546 - lr: 0.0050\n",
            "Epoch 60/1000\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 32.9361 - val_loss: 107.9072 - lr: 0.0050\n",
            "Epoch 61/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 26.5259 - val_loss: 103.7466 - lr: 0.0050\n",
            "Epoch 62/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 29.1735 - val_loss: 107.6867 - lr: 0.0050\n",
            "Epoch 63/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 27.4507 - val_loss: 109.8215 - lr: 0.0050\n",
            "Epoch 64/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 33.4157 - val_loss: 114.8673 - lr: 0.0050\n",
            "Epoch 65/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 25.1528 - val_loss: 125.6239 - lr: 0.0050\n",
            "Epoch 66/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 27.6851 - val_loss: 117.0129 - lr: 0.0050\n",
            "Epoch 67/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 29.4289 - val_loss: 109.9058 - lr: 0.0050\n",
            "Epoch 68/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 28.4041 - val_loss: 112.4386 - lr: 0.0050\n",
            "Epoch 69/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.8645 - val_loss: 112.9903 - lr: 0.0050\n",
            "Epoch 70/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 28.1460 - val_loss: 125.3224 - lr: 0.0050\n",
            "Epoch 71/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 31.8746 - val_loss: 137.5563 - lr: 0.0050\n",
            "Epoch 72/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 24.1666 - val_loss: 149.1130 - lr: 0.0050\n",
            "Epoch 73/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 30.7076 - val_loss: 157.3804 - lr: 0.0050\n",
            "Epoch 74/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.0159 - val_loss: 149.5969 - lr: 0.0050\n",
            "Epoch 75/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 30.0713 - val_loss: 125.0530 - lr: 0.0050\n",
            "Epoch 76/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 26.9915 - val_loss: 107.8796 - lr: 0.0050\n",
            "Epoch 77/1000\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 24.4450 - val_loss: 101.1719 - lr: 0.0050\n",
            "Epoch 78/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.1492 - val_loss: 105.7503 - lr: 0.0050\n",
            "Epoch 79/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 24.1588 - val_loss: 103.3490 - lr: 0.0050\n",
            "Epoch 80/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 27.0980 - val_loss: 102.5016 - lr: 0.0050\n",
            "Epoch 81/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.9090 - val_loss: 110.3767 - lr: 0.0050\n",
            "Epoch 82/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 27.6387 - val_loss: 116.6040 - lr: 0.0050\n",
            "Epoch 83/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 25.2174 - val_loss: 120.4754 - lr: 0.0050\n",
            "Epoch 84/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.6347 - val_loss: 131.3021 - lr: 0.0050\n",
            "Epoch 85/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 27.6162 - val_loss: 131.3696 - lr: 0.0050\n",
            "Epoch 86/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 26.5343 - val_loss: 140.0600 - lr: 0.0050\n",
            "Epoch 87/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 24.1554 - val_loss: 113.9922 - lr: 0.0050\n",
            "Epoch 88/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 28.6585 - val_loss: 108.6458 - lr: 0.0050\n",
            "Epoch 89/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 29.5466 - val_loss: 118.2379 - lr: 0.0050\n",
            "Epoch 90/1000\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 28.8953 - val_loss: 127.9528 - lr: 0.0050\n",
            "Epoch 91/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 23.3244 - val_loss: 131.3122 - lr: 0.0050\n",
            "Epoch 92/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 26.5275 - val_loss: 132.5846 - lr: 0.0050\n",
            "Epoch 93/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 24.1470 - val_loss: 125.6064 - lr: 0.0050\n",
            "Epoch 94/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 24.8415 - val_loss: 106.6693 - lr: 0.0050\n",
            "Epoch 95/1000\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 22.1052 - val_loss: 95.2780 - lr: 0.0050\n",
            "Epoch 96/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 24.2163 - val_loss: 99.5729 - lr: 0.0050\n",
            "Epoch 97/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 20.7479 - val_loss: 107.9629 - lr: 0.0050\n",
            "Epoch 98/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 28.5133 - val_loss: 130.5944 - lr: 0.0050\n",
            "Epoch 99/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 23.8644 - val_loss: 114.8636 - lr: 0.0050\n",
            "Epoch 100/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 24.1184 - val_loss: 113.5649 - lr: 0.0050\n",
            "Epoch 101/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 18.4817 - val_loss: 118.5360 - lr: 0.0050\n",
            "Epoch 102/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.9490 - val_loss: 123.5637 - lr: 0.0050\n",
            "Epoch 103/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.1790 - val_loss: 123.8717 - lr: 0.0050\n",
            "Epoch 104/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 21.6757 - val_loss: 127.2176 - lr: 0.0050\n",
            "Epoch 105/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 22.4294 - val_loss: 135.1104 - lr: 0.0050\n",
            "Epoch 106/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 23.8475 - val_loss: 168.9135 - lr: 0.0050\n",
            "Epoch 107/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 24.8212 - val_loss: 193.4430 - lr: 0.0050\n",
            "Epoch 108/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 24.6098 - val_loss: 150.8522 - lr: 0.0050\n",
            "Epoch 109/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 18.6787 - val_loss: 121.9931 - lr: 0.0050\n",
            "Epoch 110/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 26.3546 - val_loss: 119.6440 - lr: 0.0050\n",
            "Epoch 111/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 25.3139 - val_loss: 118.3166 - lr: 0.0050\n",
            "Epoch 112/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 22.1858 - val_loss: 114.5423 - lr: 0.0050\n",
            "Epoch 113/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 25.0634 - val_loss: 111.6522 - lr: 0.0050\n",
            "Epoch 114/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.8237 - val_loss: 123.3520 - lr: 0.0050\n",
            "Epoch 115/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 24.4450 - val_loss: 154.5117 - lr: 0.0050\n",
            "Epoch 116/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 20.7881 - val_loss: 156.9800 - lr: 0.0050\n",
            "Epoch 117/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 23.7776 - val_loss: 120.1909 - lr: 0.0050\n",
            "Epoch 118/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 19.4257 - val_loss: 116.9051 - lr: 0.0050\n",
            "Epoch 119/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 20.6708 - val_loss: 132.4974 - lr: 0.0050\n",
            "Epoch 120/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 21.6311 - val_loss: 143.4354 - lr: 0.0050\n",
            "Epoch 121/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 21.5872 - val_loss: 126.1903 - lr: 0.0050\n",
            "Epoch 122/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 23.9294 - val_loss: 121.4958 - lr: 0.0050\n",
            "Epoch 123/1000\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 18.4193 - val_loss: 117.1127 - lr: 0.0050\n",
            "Epoch 124/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.3340 - val_loss: 112.0809 - lr: 0.0050\n",
            "Epoch 125/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.2358 - val_loss: 113.0891 - lr: 0.0050\n",
            "Epoch 126/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 23.5530 - val_loss: 113.9390 - lr: 0.0050\n",
            "Epoch 127/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 22.8834 - val_loss: 115.8065 - lr: 0.0050\n",
            "Epoch 128/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.5405 - val_loss: 114.9061 - lr: 0.0050\n",
            "Epoch 129/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 19.4085 - val_loss: 107.1368 - lr: 0.0050\n",
            "Epoch 130/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 19.3592 - val_loss: 102.7056 - lr: 0.0050\n",
            "Epoch 131/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 26.5301 - val_loss: 117.5998 - lr: 0.0050\n",
            "Epoch 132/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 19.8644 - val_loss: 144.2121 - lr: 0.0050\n",
            "Epoch 133/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.8906 - val_loss: 154.9485 - lr: 0.0050\n",
            "Epoch 134/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 19.9858 - val_loss: 107.8704 - lr: 0.0050\n",
            "Epoch 135/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 19.5394 - val_loss: 103.5269 - lr: 0.0050\n",
            "Epoch 136/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 20.6367 - val_loss: 107.7362 - lr: 0.0050\n",
            "Epoch 137/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.3344 - val_loss: 110.4220 - lr: 0.0050\n",
            "Epoch 138/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 20.7971 - val_loss: 136.9913 - lr: 0.0050\n",
            "Epoch 139/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.3856 - val_loss: 110.5139 - lr: 0.0050\n",
            "Epoch 140/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15.6034 - val_loss: 101.0081 - lr: 0.0050\n",
            "Epoch 141/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15.6513 - val_loss: 100.2484 - lr: 0.0050\n",
            "Epoch 142/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 18.2982 - val_loss: 104.4622 - lr: 0.0050\n",
            "Epoch 143/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.3590 - val_loss: 105.1882 - lr: 0.0050\n",
            "Epoch 144/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 14.9203 - val_loss: 112.7628 - lr: 0.0050\n",
            "Epoch 145/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.5656 - val_loss: 111.1968 - lr: 0.0050\n",
            "Epoch 146/1000\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 17.3474 - val_loss: 107.0259 - lr: 0.0025\n",
            "Epoch 147/1000\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 18.5090 - val_loss: 104.6663 - lr: 0.0025\n",
            "Epoch 148/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 14.4375 - val_loss: 109.5290 - lr: 0.0025\n",
            "Epoch 149/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 20.5105 - val_loss: 130.3486 - lr: 0.0025\n",
            "Epoch 150/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.7309 - val_loss: 157.9794 - lr: 0.0025\n",
            "Epoch 151/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 16.6515 - val_loss: 161.7159 - lr: 0.0025\n",
            "Epoch 152/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.0314 - val_loss: 151.1536 - lr: 0.0025\n",
            "Epoch 153/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 17.8033 - val_loss: 146.5048 - lr: 0.0025\n",
            "Epoch 154/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.3356 - val_loss: 143.6175 - lr: 0.0025\n",
            "Epoch 155/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.2011 - val_loss: 138.8551 - lr: 0.0025\n",
            "Epoch 156/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.9733 - val_loss: 135.9583 - lr: 0.0025\n",
            "Epoch 157/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 19.0477 - val_loss: 126.8519 - lr: 0.0025\n",
            "Epoch 158/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 17.1962 - val_loss: 96.8680 - lr: 0.0025\n",
            "Epoch 159/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 16.4530 - val_loss: 92.2189 - lr: 0.0025\n",
            "Epoch 160/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 18.4767 - val_loss: 96.3306 - lr: 0.0025\n",
            "Epoch 161/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.2645 - val_loss: 100.6151 - lr: 0.0025\n",
            "Epoch 162/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 15.5787 - val_loss: 106.1363 - lr: 0.0025\n",
            "Epoch 163/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.7194 - val_loss: 112.8073 - lr: 0.0025\n",
            "Epoch 164/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 15.6139 - val_loss: 115.6637 - lr: 0.0025\n",
            "Epoch 165/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 16.3498 - val_loss: 117.4442 - lr: 0.0025\n",
            "Epoch 166/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 18.6294 - val_loss: 113.0218 - lr: 0.0025\n",
            "Epoch 167/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.7508 - val_loss: 108.0993 - lr: 0.0025\n",
            "Epoch 168/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 13.9153 - val_loss: 98.8291 - lr: 0.0025\n",
            "Epoch 169/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.7269 - val_loss: 94.1762 - lr: 0.0025\n",
            "Epoch 170/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 14.3323 - val_loss: 91.5566 - lr: 0.0025\n",
            "Epoch 171/1000\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 18.8619 - val_loss: 89.4474 - lr: 0.0025\n",
            "Epoch 172/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 18.5194 - val_loss: 89.8787 - lr: 0.0025\n",
            "Epoch 173/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.6226 - val_loss: 92.0684 - lr: 0.0025\n",
            "Epoch 174/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.9563 - val_loss: 96.5412 - lr: 0.0025\n",
            "Epoch 175/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 14.7108 - val_loss: 102.3518 - lr: 0.0025\n",
            "Epoch 176/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.9644 - val_loss: 110.1821 - lr: 0.0025\n",
            "Epoch 177/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.2053 - val_loss: 121.9272 - lr: 0.0025\n",
            "Epoch 178/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.3356 - val_loss: 118.5215 - lr: 0.0025\n",
            "Epoch 179/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 16.7230 - val_loss: 111.4647 - lr: 0.0025\n",
            "Epoch 180/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 14.6936 - val_loss: 106.4503 - lr: 0.0025\n",
            "Epoch 181/1000\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 11.9268 - val_loss: 103.3398 - lr: 0.0025\n",
            "Epoch 182/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.1208 - val_loss: 101.6789 - lr: 0.0025\n",
            "Epoch 183/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 13.6078 - val_loss: 103.3677 - lr: 0.0025\n",
            "Epoch 184/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 17.0836 - val_loss: 103.9469 - lr: 0.0025\n",
            "Epoch 185/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15.2699 - val_loss: 103.4653 - lr: 0.0025\n",
            "Epoch 186/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.3033 - val_loss: 102.9945 - lr: 0.0025\n",
            "Epoch 187/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 17.0188 - val_loss: 102.7496 - lr: 0.0025\n",
            "Epoch 188/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15.1202 - val_loss: 100.6758 - lr: 0.0025\n",
            "Epoch 189/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.8180 - val_loss: 99.6765 - lr: 0.0025\n",
            "Epoch 190/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.4692 - val_loss: 99.0241 - lr: 0.0025\n",
            "Epoch 191/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 15.3633 - val_loss: 99.8687 - lr: 0.0025\n",
            "Epoch 192/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.9438 - val_loss: 100.8404 - lr: 0.0025\n",
            "Epoch 193/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.4104 - val_loss: 100.5049 - lr: 0.0025\n",
            "Epoch 194/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 15.4509 - val_loss: 101.6439 - lr: 0.0025\n",
            "Epoch 195/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 12.8008 - val_loss: 102.6510 - lr: 0.0025\n",
            "Epoch 196/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.3903 - val_loss: 101.1012 - lr: 0.0025\n",
            "Epoch 197/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.3228 - val_loss: 100.3558 - lr: 0.0025\n",
            "Epoch 198/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 16.6702 - val_loss: 98.6262 - lr: 0.0025\n",
            "Epoch 199/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 14.0957 - val_loss: 99.3537 - lr: 0.0025\n",
            "Epoch 200/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.1549 - val_loss: 98.1561 - lr: 0.0025\n",
            "Epoch 201/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 15.0099 - val_loss: 96.9264 - lr: 0.0025\n",
            "Epoch 202/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 12.7042 - val_loss: 93.6985 - lr: 0.0025\n",
            "Epoch 203/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.9004 - val_loss: 90.8262 - lr: 0.0025\n",
            "Epoch 204/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.3407 - val_loss: 92.3097 - lr: 0.0025\n",
            "Epoch 205/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.9165 - val_loss: 95.2593 - lr: 0.0025\n",
            "Epoch 206/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.8237 - val_loss: 102.4092 - lr: 0.0025\n",
            "Epoch 207/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 13.3028 - val_loss: 111.0925 - lr: 0.0025\n",
            "Epoch 208/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.7445 - val_loss: 114.9994 - lr: 0.0025\n",
            "Epoch 209/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.5668 - val_loss: 110.2869 - lr: 0.0025\n",
            "Epoch 210/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 13.9283 - val_loss: 115.7912 - lr: 0.0025\n",
            "Epoch 211/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 13.1863 - val_loss: 122.8509 - lr: 0.0025\n",
            "Epoch 212/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.8961 - val_loss: 128.7330 - lr: 0.0025\n",
            "Epoch 213/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15.4033 - val_loss: 122.9509 - lr: 0.0025\n",
            "Epoch 214/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 14.5178 - val_loss: 112.0686 - lr: 0.0025\n",
            "Epoch 215/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.5935 - val_loss: 110.8371 - lr: 0.0025\n",
            "Epoch 216/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 17.9389 - val_loss: 111.7022 - lr: 0.0025\n",
            "Epoch 217/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.8852 - val_loss: 115.7848 - lr: 0.0025\n",
            "Epoch 218/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.9035 - val_loss: 115.8285 - lr: 0.0025\n",
            "Epoch 219/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 12.3118 - val_loss: 114.6891 - lr: 0.0025\n",
            "Epoch 220/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 12.3288 - val_loss: 112.7858 - lr: 0.0025\n",
            "Epoch 221/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.7382 - val_loss: 111.0028 - lr: 0.0025\n",
            "Epoch 222/1000\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 11.7466 - val_loss: 111.4363 - lr: 0.0012\n",
            "Epoch 223/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 10.9928 - val_loss: 112.6963 - lr: 0.0012\n",
            "Epoch 224/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.7918 - val_loss: 115.4352 - lr: 0.0012\n",
            "Epoch 225/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.5026 - val_loss: 124.4719 - lr: 0.0012\n",
            "Epoch 226/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.1772 - val_loss: 132.5423 - lr: 0.0012\n",
            "Epoch 227/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.0871 - val_loss: 136.0563 - lr: 0.0012\n",
            "Epoch 228/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.9711 - val_loss: 134.2397 - lr: 0.0012\n",
            "Epoch 229/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.5579 - val_loss: 132.5715 - lr: 0.0012\n",
            "Epoch 230/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.4881 - val_loss: 125.8673 - lr: 0.0012\n",
            "Epoch 231/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.7196 - val_loss: 112.9822 - lr: 0.0012\n",
            "Epoch 232/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.1933 - val_loss: 107.6658 - lr: 0.0012\n",
            "Epoch 233/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.7024 - val_loss: 107.0947 - lr: 0.0012\n",
            "Epoch 234/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.4995 - val_loss: 106.6200 - lr: 0.0012\n",
            "Epoch 235/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.5360 - val_loss: 105.1051 - lr: 0.0012\n",
            "Epoch 236/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 12.0377 - val_loss: 103.4935 - lr: 0.0012\n",
            "Epoch 237/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.6732 - val_loss: 102.7337 - lr: 0.0012\n",
            "Epoch 238/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.9507 - val_loss: 103.0739 - lr: 0.0012\n",
            "Epoch 239/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.2172 - val_loss: 107.3295 - lr: 0.0012\n",
            "Epoch 240/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 12.6749 - val_loss: 121.0413 - lr: 0.0012\n",
            "Epoch 241/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 12.4187 - val_loss: 134.6699 - lr: 0.0012\n",
            "Epoch 242/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 10.4208 - val_loss: 139.2196 - lr: 0.0012\n",
            "Epoch 243/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 12.3901 - val_loss: 133.3596 - lr: 0.0012\n",
            "Epoch 244/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.9770 - val_loss: 122.0638 - lr: 0.0012\n",
            "Epoch 245/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.0833 - val_loss: 112.9019 - lr: 0.0012\n",
            "Epoch 246/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 11.2459 - val_loss: 108.0522 - lr: 0.0012\n",
            "Epoch 247/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.3549 - val_loss: 106.7263 - lr: 0.0012\n",
            "Epoch 248/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.4309 - val_loss: 108.2651 - lr: 0.0012\n",
            "Epoch 249/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 11.6589 - val_loss: 108.5087 - lr: 0.0012\n",
            "Epoch 250/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.5080 - val_loss: 108.9435 - lr: 0.0012\n",
            "Epoch 251/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 13.5310 - val_loss: 108.0305 - lr: 0.0012\n",
            "Epoch 252/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 14.1209 - val_loss: 108.3400 - lr: 0.0012\n",
            "Epoch 253/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 12.4813 - val_loss: 108.4879 - lr: 0.0012\n",
            "Epoch 254/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 20.1704 - val_loss: 109.9356 - lr: 0.0012\n",
            "Epoch 255/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 12.0523 - val_loss: 116.3430 - lr: 0.0012\n",
            "Epoch 256/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.9059 - val_loss: 125.4863 - lr: 0.0012\n",
            "Epoch 257/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.8557 - val_loss: 129.1128 - lr: 0.0012\n",
            "Epoch 258/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 12.9364 - val_loss: 130.8162 - lr: 0.0012\n",
            "Epoch 259/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.9170 - val_loss: 131.6234 - lr: 0.0012\n",
            "Epoch 260/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.0630 - val_loss: 131.3017 - lr: 0.0012\n",
            "Epoch 261/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.9323 - val_loss: 132.8177 - lr: 0.0012\n",
            "Epoch 262/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 10.9371 - val_loss: 132.3244 - lr: 0.0012\n",
            "Epoch 263/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 11.8350 - val_loss: 127.5834 - lr: 0.0012\n",
            "Epoch 264/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 12.5853 - val_loss: 121.0661 - lr: 0.0012\n",
            "Epoch 265/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.0004 - val_loss: 117.2810 - lr: 0.0012\n",
            "Epoch 266/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.8296 - val_loss: 115.9172 - lr: 0.0012\n",
            "Epoch 267/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.2297 - val_loss: 115.2958 - lr: 0.0012\n",
            "Epoch 268/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.3295 - val_loss: 114.5709 - lr: 0.0012\n",
            "Epoch 269/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 13.3370 - val_loss: 116.2408 - lr: 0.0012\n",
            "Epoch 270/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 10.6545 - val_loss: 122.8395 - lr: 0.0012\n",
            "Epoch 271/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.3366 - val_loss: 128.0383 - lr: 0.0012\n",
            "Epoch 272/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.3765 - val_loss: 127.1631 - lr: 6.2500e-04\n",
            "Epoch 273/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.2204 - val_loss: 123.8194 - lr: 6.2500e-04\n",
            "Epoch 274/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 8.5371 - val_loss: 119.9712 - lr: 6.2500e-04\n",
            "Epoch 275/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 11.1256 - val_loss: 118.3263 - lr: 6.2500e-04\n",
            "Epoch 276/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 11.8455 - val_loss: 121.4541 - lr: 6.2500e-04\n",
            "Epoch 277/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.4334 - val_loss: 124.8066 - lr: 6.2500e-04\n",
            "Epoch 278/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 12.7867 - val_loss: 126.5020 - lr: 6.2500e-04\n",
            "Epoch 279/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 11.4877 - val_loss: 128.1900 - lr: 6.2500e-04\n",
            "Epoch 280/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 12.2055 - val_loss: 128.7569 - lr: 6.2500e-04\n",
            "Epoch 281/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.8617 - val_loss: 128.9473 - lr: 6.2500e-04\n",
            "Epoch 282/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 14.7710 - val_loss: 130.7087 - lr: 6.2500e-04\n",
            "Epoch 283/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.7126 - val_loss: 131.6728 - lr: 6.2500e-04\n",
            "Epoch 284/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 13.3450 - val_loss: 132.8738 - lr: 6.2500e-04\n",
            "Epoch 285/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 12.6603 - val_loss: 132.5355 - lr: 6.2500e-04\n",
            "Epoch 286/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.8017 - val_loss: 130.4853 - lr: 6.2500e-04\n",
            "Epoch 287/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.3210 - val_loss: 128.4519 - lr: 6.2500e-04\n",
            "Epoch 288/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.6676 - val_loss: 128.5739 - lr: 6.2500e-04\n",
            "Epoch 289/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 10.9421 - val_loss: 129.0856 - lr: 6.2500e-04\n",
            "Epoch 290/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.6079 - val_loss: 131.0086 - lr: 6.2500e-04\n",
            "Epoch 291/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 13.6644 - val_loss: 132.9016 - lr: 6.2500e-04\n",
            "Epoch 292/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 14.7173 - val_loss: 133.6583 - lr: 6.2500e-04\n",
            "Epoch 293/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 11.0286 - val_loss: 133.9658 - lr: 6.2500e-04\n",
            "Epoch 294/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.1012 - val_loss: 132.0933 - lr: 6.2500e-04\n",
            "Epoch 295/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 11.7678 - val_loss: 134.1770 - lr: 6.2500e-04\n",
            "Epoch 296/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.1650 - val_loss: 135.5480 - lr: 6.2500e-04\n",
            "Epoch 297/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 11.3031 - val_loss: 135.7899 - lr: 6.2500e-04\n",
            "Epoch 298/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 12.7750 - val_loss: 134.2612 - lr: 6.2500e-04\n",
            "Epoch 299/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 11.5895 - val_loss: 134.2566 - lr: 6.2500e-04\n",
            "Epoch 300/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.0669 - val_loss: 133.8845 - lr: 6.2500e-04\n",
            "Epoch 301/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 13.4238 - val_loss: 133.0892 - lr: 6.2500e-04\n",
            "Epoch 302/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 15.0087 - val_loss: 132.3665 - lr: 6.2500e-04\n",
            "Epoch 303/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.5315 - val_loss: 130.9719 - lr: 6.2500e-04\n",
            "Epoch 304/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.0764 - val_loss: 129.4378 - lr: 6.2500e-04\n",
            "Epoch 305/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 10.8917 - val_loss: 127.4626 - lr: 6.2500e-04\n",
            "Epoch 306/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.7767 - val_loss: 125.1609 - lr: 6.2500e-04\n",
            "Epoch 307/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 8.1637 - val_loss: 122.8094 - lr: 6.2500e-04\n",
            "Epoch 308/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 11.9497 - val_loss: 122.1697 - lr: 6.2500e-04\n",
            "Epoch 309/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.8098 - val_loss: 124.0796 - lr: 6.2500e-04\n",
            "Epoch 310/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 12.6393 - val_loss: 129.5431 - lr: 6.2500e-04\n",
            "Epoch 311/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.9067 - val_loss: 132.6765 - lr: 6.2500e-04\n",
            "Epoch 312/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 12.5574 - val_loss: 133.7078 - lr: 6.2500e-04\n",
            "Epoch 313/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.6828 - val_loss: 134.5609 - lr: 6.2500e-04\n",
            "Epoch 314/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 11.5978 - val_loss: 134.1095 - lr: 6.2500e-04\n",
            "Epoch 315/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.6212 - val_loss: 133.6548 - lr: 6.2500e-04\n",
            "Epoch 316/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 11.2617 - val_loss: 133.2922 - lr: 6.2500e-04\n",
            "Epoch 317/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 9.6943 - val_loss: 133.7500 - lr: 6.2500e-04\n",
            "Epoch 318/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 7.6779 - val_loss: 134.7563 - lr: 6.2500e-04\n",
            "Epoch 319/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 11.4464 - val_loss: 135.5902 - lr: 6.2500e-04\n",
            "Epoch 320/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 12.1527 - val_loss: 136.3905 - lr: 6.2500e-04\n",
            "Epoch 321/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 10.5202 - val_loss: 136.2025 - lr: 6.2500e-04\n",
            "Epoch 322/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 11.1876 - val_loss: 135.2172 - lr: 3.1250e-04\n",
            "Epoch 323/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 8.9907 - val_loss: 132.9708 - lr: 3.1250e-04\n",
            "Epoch 324/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.9156 - val_loss: 129.9575 - lr: 3.1250e-04\n",
            "Epoch 325/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 9.8651 - val_loss: 128.0290 - lr: 3.1250e-04\n",
            "Epoch 326/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 10.9407 - val_loss: 126.3432 - lr: 3.1250e-04\n",
            "Epoch 327/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.9921 - val_loss: 125.3329 - lr: 3.1250e-04\n",
            "Epoch 328/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 13.1886 - val_loss: 122.9970 - lr: 3.1250e-04\n",
            "Epoch 329/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.9084 - val_loss: 120.9653 - lr: 3.1250e-04\n",
            "Epoch 330/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.1014 - val_loss: 119.5816 - lr: 3.1250e-04\n",
            "Epoch 331/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 11.0664 - val_loss: 118.8829 - lr: 3.1250e-04\n",
            "Epoch 332/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 10.0326 - val_loss: 119.5639 - lr: 3.1250e-04\n",
            "Epoch 333/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 12.7914 - val_loss: 121.7015 - lr: 3.1250e-04\n",
            "Epoch 334/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 11.7075 - val_loss: 122.5435 - lr: 3.1250e-04\n",
            "Epoch 335/1000\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 10.7325 - val_loss: 125.1056 - lr: 3.1250e-04\n",
            "Epoch 336/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.6333 - val_loss: 126.9351 - lr: 3.1250e-04\n",
            "Epoch 337/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 11.4613 - val_loss: 126.8119 - lr: 3.1250e-04\n",
            "Epoch 338/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 10.1856 - val_loss: 125.4242 - lr: 3.1250e-04\n",
            "Epoch 339/1000\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 10.4636 - val_loss: 122.9446 - lr: 3.1250e-04\n",
            "Epoch 340/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 12.1124 - val_loss: 121.7816 - lr: 3.1250e-04\n",
            "Epoch 341/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 12.3394 - val_loss: 121.4819 - lr: 3.1250e-04\n",
            "Epoch 342/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.4777 - val_loss: 121.4555 - lr: 3.1250e-04\n",
            "Epoch 343/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.7934 - val_loss: 122.2407 - lr: 3.1250e-04\n",
            "Epoch 344/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.7890 - val_loss: 122.9675 - lr: 3.1250e-04\n",
            "Epoch 345/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.3181 - val_loss: 124.1604 - lr: 3.1250e-04\n",
            "Epoch 346/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 10.9158 - val_loss: 126.2059 - lr: 3.1250e-04\n",
            "Epoch 347/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 12.3213 - val_loss: 127.7788 - lr: 3.1250e-04\n",
            "Epoch 348/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 12.8351 - val_loss: 129.4749 - lr: 3.1250e-04\n",
            "Epoch 349/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 11.7856 - val_loss: 130.1375 - lr: 3.1250e-04\n",
            "Epoch 350/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 12.1431 - val_loss: 129.2815 - lr: 3.1250e-04\n",
            "Epoch 351/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.9813 - val_loss: 128.2880 - lr: 3.1250e-04\n",
            "Epoch 352/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 10.0431 - val_loss: 127.5743 - lr: 3.1250e-04\n",
            "Epoch 353/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 8.4015 - val_loss: 127.3585 - lr: 3.1250e-04\n",
            "Epoch 354/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 13.1791 - val_loss: 129.0508 - lr: 3.1250e-04\n",
            "Epoch 355/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 14.6522 - val_loss: 129.0758 - lr: 3.1250e-04\n",
            "Epoch 356/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 10.3529 - val_loss: 127.4619 - lr: 3.1250e-04\n",
            "Epoch 357/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 13.1002 - val_loss: 126.3878 - lr: 3.1250e-04\n",
            "Epoch 358/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 11.8384 - val_loss: 125.3136 - lr: 3.1250e-04\n",
            "Epoch 359/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.9092 - val_loss: 125.3865 - lr: 3.1250e-04\n",
            "Epoch 360/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 11.3655 - val_loss: 124.4301 - lr: 3.1250e-04\n",
            "Epoch 361/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 10.4962 - val_loss: 122.8698 - lr: 3.1250e-04\n",
            "Epoch 362/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 11.6941 - val_loss: 121.5864 - lr: 3.1250e-04\n",
            "Epoch 363/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 11.7556 - val_loss: 119.7932 - lr: 3.1250e-04\n",
            "Epoch 364/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.9340 - val_loss: 119.1608 - lr: 3.1250e-04\n",
            "Epoch 365/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 9.7900 - val_loss: 119.0607 - lr: 3.1250e-04\n",
            "Epoch 366/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 11.7726 - val_loss: 119.2130 - lr: 3.1250e-04\n",
            "Epoch 367/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 9.5807 - val_loss: 119.2873 - lr: 3.1250e-04\n",
            "Epoch 368/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 10.4053 - val_loss: 119.6285 - lr: 3.1250e-04\n",
            "Epoch 369/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 14.0995 - val_loss: 119.7414 - lr: 3.1250e-04\n",
            "Epoch 370/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 13.0576 - val_loss: 118.8431 - lr: 3.1250e-04\n",
            "Epoch 371/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 11.7829 - val_loss: 118.6720 - lr: 3.1250e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Type_I_crime_amount  Type_II_crime_amount\n",
              "0                  11.0                  38.0\n",
              "1                  10.0                  36.0\n",
              "2                   9.0                  34.0\n",
              "3                   7.0                  29.0\n",
              "4                   8.0                  24.0\n",
              "5                   8.0                  24.0\n",
              "6                  12.0                  24.0\n",
              "7                  13.0                  24.0\n",
              "8                  14.0                  25.0\n",
              "9                  13.0                  26.0\n",
              "10                 13.0                  25.0\n",
              "11                 14.0                  26.0\n",
              "12                 13.0                  26.0\n",
              "13                 13.0                  25.0\n",
              "14                 13.0                  26.0\n",
              "15                 13.0                  25.0\n",
              "16                 11.0                  24.0\n",
              "17                 10.0                  24.0\n",
              "18                  9.0                  26.0\n",
              "19                  8.0                  27.0\n",
              "20                  8.0                  28.0\n",
              "21                  7.0                  30.0\n",
              "22                  8.0                  31.0\n",
              "23                  8.0                  32.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de26e899-9b49-4012-bfae-c15f6fc5eb31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type_I_crime_amount</th>\n",
              "      <th>Type_II_crime_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>14.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>13.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>8.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>8.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>7.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de26e899-9b49-4012-bfae-c15f6fc5eb31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de26e899-9b49-4012-bfae-c15f6fc5eb31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de26e899-9b49-4012-bfae-c15f6fc5eb31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_predict.to_csv(\"/content/drive/MyDrive/DC2/urban_old_prediction.csv\", index = False)\n",
        "df_real_predict.to_csv(\"/content/drive/MyDrive/DC2/urban_new_prediction.csv\", index = False)"
      ],
      "metadata": {
        "id": "-MMEmCJNw8RD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
